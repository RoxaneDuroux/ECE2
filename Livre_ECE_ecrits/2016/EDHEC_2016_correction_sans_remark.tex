\documentclass[11pt]{article}%
\usepackage{geometry}%
\geometry{a4paper,
 lmargin = 2cm,rmargin = 2cm,tmargin = 2.5cm,bmargin = 2.5cm}

\input{../macros_Livre.tex}

\pagestyle{fancy} %
\lhead{ECE2 \hfill Mathématiques\\
} %
\chead{\hrule} %
\rhead{} %
\lfoot{} %
\cfoot{} %
\rfoot{\thepage} %

%%% Pour ce corrigé uniquement
\renewcommand{\id}{Id}

\renewcommand{\headrulewidth}{0pt}% : Trace un trait de séparation
 % de largeur 0,4 point. Mettre 0pt
 % pour supprimer le trait.

\renewcommand{\footrulewidth}{0.4pt}% : Trace un trait de séparation
 % de largeur 0,4 point. Mettre 0pt
 % pour supprimer le trait.

\setlength{\headheight}{14pt}

\title{\bf \vspace{-2cm} EDHEC 2016} %
\author{} %
\date{} %
\begin{document}

\maketitle %
\vspace{-1.4cm}\hrule %
\thispagestyle{fancy}

%\vspace*{.2cm}

%%DEBUT

\section*{Exercice 1}
\noindent
On désigne par $Id$ l'endomorphisme identité de $\R^3$ et par $I$ la
matrice identité de $\M{3}$. \\
On note $\B = (e_{1},e_{2},e_{3})$ la base canonique de $\R^3$ et on
considère l'endomorphisme $f$ de $\R^3$ dont la matrice dans la base
$\B$ est : $A =
\begin{smatrix}
  3 & -1 & 1\\
  2 & 0 & 2\\
  1 & -1 & 3
\end{smatrix}
$. 
\begin{noliste}{1.}
  \setlength{\itemsep}{4mm}
\item Calculer $A^{2}-4A$ puis déterminer un polynôme annulateur de
  $A$ de degré $2$.

  \begin{proof}~
    \begin{noliste}{$\sbullet$}
    \item Tout d'abord : $A^2=
      \begin{smatrix} 
        3 & -1 & 1\\
        2 & 0 & 2\\
        1 & -1 & 3
      \end{smatrix}
      \times
      \begin{smatrix} 
        3 & -1 & 1\\
        2 & 0 & 2\\
        1 & -1 & 3
      \end{smatrix}      
      =
      \begin{smatrix} 
        8 & -4 & 4\\
        8 & -4 & 8\\
        4 & -4 & 8
      \end{smatrix}
      $.\\[.2cm]

    \item Ainsi : $A^2 - 4A =
      \begin{smatrix} 
        8 & -4 & 4\\
        8 & -4 & 8\\
        4 & -4 & 8
      \end{smatrix}
      -
      \begin{smatrix}
        12 & -4 & 4\\
        8 & 0 & 8\\
        4 & -4 & 12
      \end{smatrix}
      = 
      \begin{smatrix}
        -4 & 0 & 0 \\
        0 & -4 & 0 \\
        0 & 0 & -4
      \end{smatrix}
      -4I$.%
      \conc{$A^2 - 4A = -4I$}  %
    \end{noliste}
    \conc{Donc $P(X) = X^2 - 4X + 4$ est {\bf un} polynôme annulateur
      de degré $2$ de $A$.}
        
    ~\\[-1.2cm]
  \end{proof}

\item
  \begin{noliste}{a)}
    \setlength{\itemsep}{2mm}
  \item En déduire la seule valeur propre de $A$ (donc aussi de $f$ ).

    \begin{proof}~
      \begin{noliste}{$\sbullet$}
      \item On remarque que $P(X) = X^2 -4X +4 = (X-2)^2$. Ainsi,
        l'unique racine de $P$ est $2$.\\
        Or le spectre de $A$ est inclus dans l'ensemble des racines
        d'un polynôme annulateur de $A$.%
        \conc{Autrement dit : $\spc(A) \subset \{2\}$.}


        %\newpage


        

      \item Montrons maintenant que $2$ est une valeur propre de $A$
        (\ie $\{2\} \subset \spc(A)$).
	\[
        \begin{array}{rcl}
          \rg(A-2I) & = & \rg %
          \left(
            \begin{smatrix}
              1 & -1 & 1 \\
              2 & -2 & 2 \\
              1 & -1 & 1
            \end{smatrix}
          \right) %
          = %
          \rg %
          \left(
            \begin{smatrix}
              1 \\ 
              2 \\
              1
            \end{smatrix}, %
            \begin{smatrix}
              - 1 \\ 
              - 2 \\
              - 1
            \end{smatrix}, %
            \begin{smatrix}
              1 \\ 
              2 \\
              1
            \end{smatrix}          
          \right)
          \\[.8cm]
          & = &
          \dim( %
          \ \Vect{%
            \begin{smatrix}
              1 \\ 
              2 \\
              1
            \end{smatrix}, %
            \begin{smatrix}
              - 1 \\ 
              - 2 \\
              - 1
            \end{smatrix}, %
            \begin{smatrix}
              1 \\ 
              2 \\
              1
            \end{smatrix}          
          } \ ) %
          \\[.8cm]
          & = &
          \dim( \ %
          \Vect{%
            \begin{smatrix}
              1 \\ 
              2 \\
              1
            \end{smatrix} %
          } \ ) %
          \ = \ 1 <3
        \end{array}        
        \]
	La matrice $A-2I$ n'est pas inversible, ce qui signifie que
        $2$ est valeur propre de $A$.
      \end{noliste}
      \conc{$\spc(A) = \spc(f) = \{2\}$}
      
      ~\\[-1.2cm]
    \end{proof}		

  \item La matrice $A$ est-elle diagonalisable ? Est-elle inversible ?
  \end{noliste}

    \begin{proof}~
      \begin{noliste}{$\sbullet$}
      \item D'après la question précédente, $A$ possède $2$ comme
        unique valeur propre. % $\spc(A) = \{2\}$.
      \item Supposons par l'absurde que $A$ est diagonalisable.\\
        Il existe alors $P \in \M{3}$ inversible telle que : 
        \[
        A = P
        \begin{smatrix}
          2 & 0 & 0 \\
          0 & 2 & 0 \\
          0 & 0 & 2           
        \end{smatrix}
        P^{-1} %
        = %
        P \, (2 \, I_3) \, P^{-1} %
        = %
        2 \, PP^{-1} %
        = %
        2 \, I_3
        \]
        ce qui est impossible puisque $A \neq 2 \, I_3$.%
	\conc{$A$ n'est pas diagonalisable.}
	
      \item Montrons que $A$ est inversible.\\
	On sait que $\spc(A) = \{2\}$. Donc en particulier, $0$ n'est
        pas valeur propre de $A$. %
        \conc{Ainsi $A$ est inversible.}
      \end{noliste}
    ~\\[-1.2cm]
  \end{proof}		

\item Déterminer une base $(u_{1},u_{2})$ du sous-espace propre de $f$
  associé à la valeur propre de $f$.

  \begin{proof}~
    \begin{noliste}{$\sbullet$}
    \item Soit $u = (x, y, z) \in \R^3$. Notons $U = \Mat_{\B}(u) =
      \begin{smatrix}
        x \\
        y \\
        z
      \end{smatrix}
      $.
      \[
      \begin{array}{rcl}
        u \in E_2(f) & \Longleftrightarrow & f(u) = 2 \ u 
        \\[.2cm]
        & \Longleftrightarrow & (f - 2 \ Id) (u) = 0
        \\[.2cm]
        & \Longleftrightarrow & (A - 2 \ I_3) \ U = 0 
        \\[.2cm]
        & \Longleftrightarrow & 
        \left\{
          \begin{array}{rcrcrcl}
            x & - & y & + & z & = & 0 \\
            2 \ x & - & 2 \ y & + & 2 \ z & = & 0 \\
            x & - & y & + & z & = & 0 
          \end{array}
        \right.
        \\[.2cm]
        &
        \begin{arrayEq}
          L_2 \leftarrow L_2 - 2 L_1 \\
          L_3 \leftarrow L_3 - L_1 
        \end{arrayEq}
        & 
        \left\{
          \begin{array}{rcrcrcl}
            \ x & - & y & + & z & = & 0 
          \end{array}
        \right.
        \\[.2cm]
        & \Longleftrightarrow & 
        \left\{
          \begin{array}{lclcl}
            \ x & = & y & - & z
          \end{array}
        \right.
      \end{array}
      \]
      % {\it (on utilise $2$ variables auxiliaires - $x$ et $y$ ici -
      %   pour faire apparaître le système sous forme échelonnée)}\\
      On en déduit : %~\\[-.6cm]
      \[
      \begin{array}{rcl}
        E_{2}(f) & = & 
        \left\{%
          u = (x, y, z) \in \R^3
          \ \ | \ \ 
          f(u) = 2u
        \right\} \\[.4cm]
        & = & 
        \left\{%
          u = (x, y, z) \in \R^3
          \ \ | \ \ 
          x = y - z 
        \right\} \\[.4cm]
        & = & 
        \left\{%
          (y - z, y, z) \in \R^3
          \ \ | \ \ 
          y \in \R, \ z \in \R
        \right\} \\[.4cm]
        & = & 
        \left\{%
          y \cdot (1, 1, 0) + z \cdot (-1, 0, 1) \in \R^3
          \ \ | \ \ 
          y \in \R, \ z \in \R
        \right\} \\[.4cm]
        & = & 
        \Vect{ %
          (1, 1, 0), (-1, 0, 1) %
        }
      \end{array} 
      \]

    \item Notons $u_1 = (1,1,0)$ et $u_2 = (-1,0,1)$. La famille
      $(u_1, u_2)$ est :
      \begin{noliste}{$\stimes$}
      \item génératrice de $E_2(f)$.
      \item libre car constituée de {\bf deux} vecteurs non
        colinéaires.
      \end{noliste}
      C'est donc une base de $E_2(f)$.
    \end{noliste}
    \conc{Ainsi $(u_1,u_2)$ est une base de $E_2(f)$.}


    %\newpage


    ~\\[-1.4cm]
  \end{proof}

\item 
  \begin{noliste}{a)}
    \setlength{\itemsep}{2mm}
  \item On pose $u_{3} = e_{1} + e_{2} + e_{3}$. Montrer que la
    famille $(u_{1},u_{2},u_{3})$ est une base de $\R^{3}$.

    \begin{proof}~
      \begin{noliste}{$\sbullet$}
      \item Tout d'abord : $u_3 = e_1+e_2+e_3 = (1,0,0) + (0,1,0) +
        (0,0,1) = (1,1,1)$.
      \item Montrons que la famille $\big((1,1,0), (-1,0,1),
        (1,1,1)\big)$ est libre.\\
        Soit $(\lambda_1, \lambda_2, \lambda_3) \in \R^3$. Supposons :
        \[
        \lambda_1 \cdot (1,1,0) + \lambda_2 \cdot (-1,0,1) + \lambda_3
        \cdot (1,1,1) = (0,0,0)
        \]
        Ceci équivaut au système :\\[-.5cm]
	\[
        \begin{array}{cl}
          & 
          \left\{
            \begin{array}{rcrcrcl}
              \ \lambda_1 & - & \lambda_2 & + & \lambda_3 & = & 0 \\
              \ \lambda_1 & & & + & \lambda_3 & = & 0 \\
              & &\lambda_2 & + & \lambda_3 & = & 0
            \end{array}
          \right.
          \\[.8cm]
          \begin{arrayEq}
            L_2 \leftarrow L_2 - L_1
          \end{arrayEq}
          & 
          \left\{
            \begin{array}{rcrcrcl}
              \ \lambda_1 & - & \lambda_2 & + & \lambda_3 & = & 0 \\
              & & \lambda_2 & & & = & 0 \\
              & &\lambda_2 & + & \lambda_3 & = & 0
            \end{array}
          \right.
          \\[.8cm]
          \begin{arrayEq}
            L_3 \leftarrow L_3 - L_2
          \end{arrayEq}
          &	
          \left\{
            \begin{array}{rcrcrcl}
              \ \lambda_1 & - & \lambda_2 & + & \lambda_3 & = & 0 \\
              & & \lambda_2 & & & = & 0 \\
              & & & & \lambda_3 & = & 0
            \end{array}
          \right.
          \\[.8cm]
          \Longleftrightarrow 
          &
          \left\{
            \begin{array}{l}
              \lambda_1 = \lambda_2 = \lambda_3 = 0
            \end{array}
          \right.\\%[.2cm]
          & \multicolumn{1}{R{5cm}}{\it (par remontées successives)}
        \end{array}
        \]
        La famille $(u_1,u_2,u_3)$ est donc libre.
	
      \item De plus, $\Card((u_1, u_2, u_3)) = 3 = \dim(\R^3)$. %
        \conc{$(u_1,u_2,u_3)$ est donc une base de $\R^3$.}~\\[-1.2cm]
      \end{noliste}
      ~\\[-1.4cm]
    \end{proof}		


    %\newpage


  \item Vérifier que la matrice $T$ de $f$ dans la base
    $(u_{1},u_{2},u_{3})$ est triangulaire et que ses éléments
    diagonaux sont tous égaux à 2.

    \begin{proof}~\\
      Notons $U_1 = \Mat_{\B}(u_1) =
        \begin{smatrix}
          1 \\
          1 \\
          0
        \end{smatrix}$, $U_2 = \Mat_{\B}(u_2) =
        \begin{smatrix}
          -1 \\
          0 \\
          1
        \end{smatrix}$, $U_3 = \Mat_{\B}(u_3) = 
        \begin{smatrix}
          1 \\
          1 \\
          1
        \end{smatrix}$.
      \begin{noliste}{$\sbullet$}
      \item On a démontré précédemment que $u_1 \in E_2(f)$. Ainsi : $
        f(u_1) = 2 \cdot u_1 + 0 \cdot u_2+0\cdot u_3 $.\\[.2cm]
        On en déduit que $\Mat_{(u_1, u_2, u_3)}(f(u_1)) =
        \begin{smatrix}
          2 \\
          0 \\
          0
        \end{smatrix}
        $.
        % $\Mat_{\B}(f(u_1)) = \Mat_{\B}(f) \times \Mat_{\B}(u_1) = A
        % \times U_1 =
        % \begin{smatrix}
        %   3 & -1 & 1\\
        %   2 & 0 & 2\\
        %   1 & -1 & 3
        % \end{smatrix}
        %         % \times
        % \begin{smatrix}
        %   1 \\
        %   1 \\
        %   0
        % \end{smatrix}
        % = 
        % \begin{smatrix}
        %   2 \\
        %   2 \\
        %   0
        % \end{smatrix}
        % = 2 \cdot
        % \begin{smatrix}
        %   1 \\
        %   1 \\
        %   0
        % \end{smatrix}
        % $\\        

      \item On a démontré précédemment que $u_2 \in E_2(f)$. Ainsi : $
        f(u_2) = 0 \cdot u_1 + 2 \cdot u_2+0\cdot u_3 $.\\[.2cm]
        On en déduit que $\Mat_{(u_1, u_2, u_3)}(f(u_2)) =
        \begin{smatrix}
          0 \\
          2 \\
          0
        \end{smatrix}
        $.
        % $\Mat_{\B}(f(u_2)) = \Mat_{\B}(f) \times
        % \Mat_{\B}(u_2) = A \times U_2 =
        % \begin{smatrix}
        %   3 & -1 & 1\\
        %   2 & 0 & 2\\
        %   1 & -1 & 3
        % \end{smatrix}
        %         % \times
        % \begin{smatrix}
        %   -1 \\
        %   0 \\
        %   1
        % \end{smatrix}
        % = 
        % \begin{smatrix}
        %   3 \\
        %   0 \\
        %   3
        % \end{smatrix}
        % = 3 \cdot
        % \begin{smatrix}
        %   -1 \\
        %   0 \\
        %   1
        % \end{smatrix}
        % $
        
      \item $\Mat_{\B}(f(u_3)) = \Mat_{\B}(f) \times
        \Mat_{\B}(u_3) = A \times U_3 =
        \begin{smatrix}
          3 & -1 & 1\\
          2 & 0 & 2\\
          1 & -1 & 3
        \end{smatrix}
        % \times
        \begin{smatrix}
          1 \\
          1 \\
          1
        \end{smatrix}
        = 
        \begin{smatrix}
          3 \\
          4 \\
          3
        \end{smatrix}       
        $.\\[.2cm]
        On cherche alors à décomposer ce vecteur suivant $(U_1, U_2,
        U_3)$.\\
        Autrement dit, on cherche $(\alpha, \beta, \gamma) \in \R^3$
        tel que $\begin{smatrix}
          3 \\
          4 \\
          3
        \end{smatrix} 
        = %
        \alpha \cdot
        \begin{smatrix}
          1 \\
          1 \\
          0
        \end{smatrix} %
        + %
        \beta \cdot
        \begin{smatrix}
          -1 \\
          0 \\
          1
        \end{smatrix} %
        + %
        \gamma \cdot
        \begin{smatrix}
          1 \\
          1 \\
          1
        \end{smatrix} %
        $.\\[.2cm]
        Ce qui équivaut au système :
        \[
        \begin{array}{cl}
          &
          \left\{
            \begin{array}{rcrcrcr}
              \ \alpha & - & \beta & + & \gamma & = & 3 \\
              \ \alpha & & & + & \gamma & = & 4 \\
              & & \beta & + & \gamma & = & 3
            \end{array}
          \right.
          \\[.8cm]
          \begin{arrayEq}
            L_2 \leftarrow L_2 - L_1
          \end{arrayEq}
          &
          \left\{
            \begin{array}{rcrcrcr}
              \ \alpha & - & \beta & + & \gamma & = & 3 \\
              & & \beta & & & = & 1 \\
              & & \beta & + & \gamma & = & 3
            \end{array}
          \right.
          \\[.8cm]
          \begin{arrayEq}
            L_3 \leftarrow L_3 - L_2
          \end{arrayEq}
          &
          \left\{
            \begin{array}{rcrcrcr}
              \ \alpha & - & \beta & + & \gamma & = & 3 \\
              & & \beta & & & = & 1 \\
              & & & & \gamma & = & 2
            \end{array}
          \right.
          \\[.8cm]
          \begin{arrayEq}
            L_1 \leftarrow L_1 - L_3 
          \end{arrayEq}
          &
          \left\{
            \begin{array}{rcrcrcr}
              \ \alpha & - & \beta & & & = & 1 \\
              & & \beta & & & = & 1 \\
              & & & & \gamma & = & 2
            \end{array}
          \right.
          \\[.8cm]
          \begin{arrayEq}
            L_1 \leftarrow L_1 + L_2
          \end{arrayEq}
          &
          \left\{
            \begin{array}{rcrcrcr}
              \ \alpha & & & & & = & 2 \\
              & & \beta & & & = & 1 \\
              & & & & \gamma & = & 2
            \end{array}
          \right.
        \end{array}
        \]
        On en déduit que $f(u_3) = 2 \cdot u_1 + 1 \cdot u_2 + 2
        \cdot u_3$.\\
        Et ainsi : $\Mat_{(u_1, u_2, u_3)}(f(u_3)) =
        \begin{smatrix}
          2 \\
          1 \\
          2
        \end{smatrix}
        $.
      \end{noliste}
      \conc{Ainsi : $T = \Mat_{(u_1, u_2, u_3)}(f) =
          \begin{smatrix}
            2 & 0 & 2 \\
            0 & 2 & 1 \\ 
            0 & 0 & 2
          \end{smatrix}
          $.}~\\[-1.2cm]
    \end{proof}

  \item En écrivant $T = 2I + N$, déterminer, pour tout entier naturel
    $n$, la matrice $T^{n}$ comme combinaison linéaire de $I$ et $N$,
    puis de $I$ et $T$.

    \begin{proof}~\\
      Soit $n\in\N^*$.
      \begin{noliste}{$\sbullet$}
      \item D'après l'énoncé, $N = T - 2 \cdot I =
        \begin{smatrix}
          0 & 0 & 2 \\ 
          0 & 0 & 1 \\ 
          0 & 0 & 0
        \end{smatrix}
        $.
                
      \item De plus : $N^2 = 
        \begin{smatrix}
          0 & 0 & -1 \\ 
          0 & 0 & -2 \\ 
          0 & 0 & 0
        \end{smatrix}
        \times 
        \begin{smatrix}
          0 & 0 & -1 \\ 
          0 & 0 & -2 \\ 
          0 & 0 & 0
        \end{smatrix}
        = 
        \begin{smatrix}
          0 & 0 & 0 \\ 
          0 & 0 & 0 \\ 
          0 & 0 & 0
        \end{smatrix}$.\\[.2cm]
        On en déduit, par une récurrence immédiate, que pour tout $k
        \geq 2$, $N^k=0$.\\
        {\it (on peut aussi noter que pour tout $k \geq 2$, $N^k= N^2
          \ N^{k-2} = 0 \times N^{k-2} = 0$)}

      \item Les matrices $2I$ et $N$ commutent puisque $I$ commute
        avec toute matrice carrée de même ordre. \\
        On peut donc appliquer la formule du binôme de Newton.
        \[
	\begin{array}{rcl@{\quad}>{\it}R{4cm}}
          T^{n} & = & (2 \, I+N)^n 
          \\[.1cm]
          & = & \Sum{k=0}{n} \dbinom{n}{k} \ (2 \, I)^{n-k} \ N^k 
          \ = \ \Sum{k=0}{n} \dbinom{n}{k} \ 2^{n-k} \, I^{n-k} \ N^k 
          \\[.5cm]
          & = & \Sum{k=0}{n} \dbinom{n}{k} \ 2^{n-k} \, I \ N^k 
          \ = \ \Sum{k=0}{n} \dbinom{n}{k} \ 2^{n-k} \ N^k & (car on a
          : \\ $\forall j \in \N, \ I^j = I$)
          \nl
          \nl[-.1cm]
          & = & \Sum{k=0}{1} \dbinom{n}{k} \ 2^{n-k} \ N^k +
          \bcancel{\Sum{k=2}{n} \dbinom{n}{k} \ 2^{n-k} \ N^k} & (ce
          découpage est \\ valable car $n \geq 1$) 
          \nl
          \nl[-.1cm]
          & = & \Sum{k=0}{1} \dbinom{n}{k} \ 2^{n-k} \ N^k & (car on a
          montré : \\ $\forall k \geq 2, \ N^k = 0$)
          \nl
          \nl[-.1cm]
          & = & \multicolumn{2}{l}{\dbinom{n}{0} \ 2^n \ N^0  +
            \dbinom{n}{1} \ 2^{n-1} \ N^1 
            % \\[.5cm]
            \ = \ 2^n \ I + n \ 2^{n-1} \ N}
        \end{array}
        \]

      \item Enfin : $2^0 \ I + 0 \ 2^{-1} \ N = I$ et $T^0 = I$.\\
        La formule précédente reste valable pour $n = 0$.%
        \conc{Ainsi, pour tout $n\in\N$, \ $T^n = 2^n \ I + n\ 2^{n-1}
          \ N$.}

      \item De plus, comme $N = T-2I$, on obtient :
	\[
	T^n \ = \ 2^n \ I + n \ 2^{n-1} \ (T-2I) \ = \ 2^n \ I + n \
        2^{n-1} \ T - n \ 2^n \ I \ = \ n \ 2^{n-1} \ T - (n-1) \ 2^n
        \ I
	\]
      \end{noliste}
      \conc{Pour tout $n\in\N$, \ $T^n = n \ 2^{n-1} \ T - (n-1) \ 2^n
        \ I$.}~\\[-1.3cm]
      ~\\[-1.4cm]
    \end{proof}
  \end{noliste}


%\newpage


\item
  \begin{noliste}{a)}
    \setlength{\itemsep}{2mm}
  \item Expliquer pourquoi l'on a :
    \[
    \forall n\in\N, \ A^{n} = n2^{n-1} \ A - (n-1) \ 2^{n} \ I
    \]

    \begin{proof}~\\
      Soit $n \in \N$. Notons $\B' = (u_1, u_2, u_3)$
      \begin{noliste}{$\sbullet$}
      \item Remarquons tout d'abord, à l'aide de la question précédente :
        \[
        \begin{array}{C{.8cm}rcl@{\quad}>{\it}R{4cm}}
          & T^n & = & n2^{n-1} \ T - (n-1) \ 2^{n} \ I 
          \\[.4cm]
          Ainsi & \big( \Mat_{\B'}(f) \big)^n & = & n2^{n-1} \ \Mat_{\B'}(f) -
          (n-1) \ 2^{n} \ \Mat_{\B'}(\id) & (par définition \\ de $T$ et $I$)
          \nl
          \nl[-.2cm]
          & & = & \Mat_{\B'} \big( n2^{n-1} \ f -
          (n-1) \ 2^{n} \ \id \big) & (par linéarité de l'application
          $\Mat_{\B'}(.)$)
        \end{array}
        \]
        Enfin, comme $\big( \Mat_{\B'}(f) \big)^n = \Mat_{\B'}(f^n)$,
        on obtient :
        \[
        \Mat_{\B'}(f^n) \ = \ \Mat_{\B'} \big( n2^{n-1} \ f - (n-1) \
        2^{n} \ \id \big)
        \]
        L'application $\Mat_{\B'}(.)$ étant bijective, on en conclut
        : %
        \conc{$f^n \ = \ n2^{n-1} \ f - (n-1) \ 2^{n} \ \id$}

      \item En appliquant $\Mat_{\B}(.)$ de part et d'autre de cette
        égalité, on obtient, à l'aide des propriétés listées au-dessus
        :
        \[
        \Mat_{\B}(f^n) \ = \ n2^{n-1} \ \Mat_{\B}(f) - (n-1) \ 2^{n} \
        \Mat_{\B}(\id)
        \]
        \conc{Ainsi : $A^n = n 2^{n-1} \ A - (n-1) \, 2^n \ I$}
      \end{noliste}
      
      ~\\[-1.4cm]
    \end{proof}
    
  \item Utiliser le polynôme annulateur obtenu à la première question
    pour déterminer $A^{-1}$ en fonction de $I$ et de $A$.

    \begin{proof}~\\
      D'après la question \itbf{1.}, $A^2 - 4A = -4I$.\\[.2cm]
      On en déduit que $-\dfrac{1}{4} \ (A^2 - 4A) = I$. Et ainsi :
      \[
      A \times \left(-\dfrac{1}{4} \ (A - 4I)\right) = I
      \]
      \conc{On en conclut que $A$ est inversible, d'inverse : $A^{-1}
        = -\dfrac{1}{4} \ (A - 4I)$.}~\\[-1cm]
    \end{proof}

  \item Vérifier que la formule trouvée à la question \itbf{5a} reste
    valable pour $n = -1$.

    \begin{proof}~\\
      Si $n=-1$, on obtient :
      \[
      \begin{array}{rcl}
        n \ 2^{n-1} \ A - (n-1) \ 2^n \ I & = & (-1)\ 2^{-1-1}\ A - (-1-1)\
        2^{-1}\ I 
        \\[.2cm]
        & = & (-1) \ \dfrac{1}{2^2} \ A - (-2) \ \dfrac{1}{2} \ I \ = \ 
        -\dfrac{1}{4} \ A + I 
        \\[.2cm]
        & = & -\dfrac{1}{4} (A - 4I) \ = \ A^{-1}
      \end{array}
      \]
      \conc{Ainsi, la formule trouvée à la question \itbf{5.a)} reste
        valable pour $n=-1$.}~\\[-1.2cm]
    \end{proof}
  \end{noliste}
\end{noliste}


%\newpage


\section*{Exercice 2}
\noindent
Pour chaque entier naturel $n$, on définit la fonction $f_{n}$ par :
$\forall x\in[n, + \infty[, \ f_{n}(x) = \dint{n}{x} \ee^{\sqrt{t}} \dt$.
\begin{noliste}{1.}
  \setlength{\itemsep}{4mm}
\item Étude de $f_{n}$.
  \begin{noliste}{a)}
    \setlength{\itemsep}{2mm}
  \item Montrer que $f_{n}$ est de classe $\Cont{1}$ sur $[n, +
    \infty[$ puis déterminer $f'_{n}(x)$ pour tout $x$ de $[n,
    +\infty[$.\\
    Donner le sens de variation de $f_{n}$.

    \begin{proof}~\\%
      Dans la suite, notons $g$ la fonction $g : t \mapsto
      \ee^{\sqrt{t}}$.\\
      Soit $n \in \N$.
      \begin{noliste}{$\sbullet$}
      \item La fonction $g$ est continue sur $[n, +\infty[$ car elle
        est la composée $g = g_2 \circ g_1$ où :
      \end{noliste}
      \begin{noliste}{$\stimes$}
      \item $g_1 : t \mapsto \sqrt{t}$ est :
        \begin{liste}{$-$}
        \item continue sur $[n, +\infty[$ (car $n \geq 0$),
        \item telle que $g_1([n, +\infty[) \subset \R$.
        \end{liste}
        % \begin{noliste}{$\stimes$}
      \item $g_2 : t \mapsto \exp(t)$, continue sur $\R$.
      \end{noliste}
      Ainsi, $g$ admet une primitive $G$ de classe $\Cont{1}$ sur $[n,
      +\infty[$.
      \begin{noliste}{$\sbullet$}
      \item Soit $x \in [n, +\infty[$. Par définition :
        \[
        f_n(x) = \dint{n}{x} \ee^{\sqrt{t}} \dt = \Prim{G(t)}{n}{x} =
        G(x)- G(n)
        \]        
        \conc{La fonction $f_n$ est de classe $\Cont{1}$ sur
          $[n,+\infty[$ car $G$ l'est.}%
        {\it ($f_n$ est la somme d'une fonction de classe $\Cont{1}$
          sur $[n,+\infty[$ et d'une constante)}%

      \item De plus :
        \[
        f_n'(x) = G'(x)-0 = g(x) = \ee^{\sqrt{x}}
        \]
        \conc{$\forall x \in [n,+\infty[$, $f_n'(x)= \ee^{\sqrt{x}}$}

      \item On remarque enfin que $f_n'(x) = \ee^{\sqrt{x}} > 0$.%
        \conc{La fonction $f_n$ est strictement croissante sur $[n,
          +\infty[$.}%~\\[-1.2cm]
      \end{noliste}
      ~\\[-1.4cm]
    \end{proof}

  \item En minorant $f_{n}(x)$, établir que $\dlim{x \tend +\infty}
    f_{n}(x) = + \infty$.

    \begin{proof}~\\
      Soit $x \in [n, +\infty[$.
      \begin{noliste}{$\sbullet$}
      \item Soit $t \in [n,x]$. Remarquons tout d'abord :
        \[
        \begin{array}{rcl@{\quad}>{\it}R{5.5cm}}
          t \ \geq \ n & \Leftrightarrow & \sqrt{t} \ \geq \ \sqrt{n}
          & (car $t\mapsto  \sqrt{t}$ est strictement \\ croissante sur $\R_+$)
          \nl
          \nl[-.2cm]
          & \Leftrightarrow & \ee^{\sqrt{t}} \ \geq \ \ee^{\sqrt{n}} & (car 
          $t\mapsto \ee^t$ est strictement \\ croissante sur $\R$)
          \nl
        \end{array}
        \]
        \conc{$\forall t \in [n,x]$, \ $g(t) \ \geq \ \ee^{\sqrt{n}}$}

      \item Par croissance de l'intégrale, les bornes étant dans
        l'ordre croissant ($x \geq n$) :
        \[
        \begin{array}{cccl}
          \dint{n}{x} \ee^{\sqrt{t}}\dt & \geq & \dint{n}{x}
          \ee^{\sqrt{n}} \dt 
          \\[.4cm]
          \shortparallel & & \shortparallel
          \\[.2cm]
          f_n(x) & \geq & \ee^{\sqrt{n}} \ (x - n) & \tendx{+\infty} +\infty
        \end{array}
        \]
        En effet, $\ee^{\sqrt{n}} > 0$ et $\dlim{x \tend +\infty}
        (x-n) = +\infty$.
      \end{noliste}
      \conc{On en déduit, par théorème de comparaison : $\dlim{x
          \tend +\infty} f_n(x) = +\infty$.}~\\[-1.15cm]
      ~\\[-1.2cm]
    \end{proof}

  \item En déduire que pour chaque entier naturel $n$, il existe un
    unique réel, noté $u_n$, élément de $[n, + \infty[$, tel que
    $f_{n}(u_n) = 1$.

    \begin{proof}~\\
      Soit $n \in \N$.
      \begin{noliste}{$\sbullet$}
      \item Notons tout d'abord : $f_n(n) = \dint{n}{n}
        \ee^{\sqrt{t}}\dt = 0$.
        % \item Avec les questions \itbf{1.a)} et \itbf{1.b)}, on
        %   obtient le tableau de variations suivant :     
        % \begin{center}
        %   \begin{tikzpicture}[scale=0.8, transform shape]
        %     \tkzTabInit[lgt=4,espcl=3] %
        %     { %
        %       $x$ /1, %
        %       Signe de $f_n'(x)$ /1, %
        %       Variations de $f_n$ /2 } %
        %     {$n$, $+\infty$} %
        %     \tkzTabLine{ , + , } %
        %     \tkzTabVar{-/$0$, +/$+\infty$} %
        %   \end{tikzpicture}
        % \end{center}

      \item La fonction $f_n$ est :
        \begin{noliste}{$\stimes$}
        \item continue sur l'intervalle $[n,+\infty[$,
        \item strictement croissante sur $[n,+\infty[$.
        \end{noliste}
        Ainsi, $f_n$ réalise une bijection de $[n,+\infty[$ dans
        $f_n\big([n,+\infty[\big)$.
        \[
        f_n\big([n,+\infty[\big) = [f_n(n), \dlim{x \tend +\infty}
        f_n(x) [ \ = [0, +\infty[
        \]

      \item Comme $1 \in [0, +\infty[$, on en déduit que $1$ admet un
        unique antécédent $u_n \in [n, +\infty[$ par la fonction
        $f_n$.
      \end{noliste}
      \conc{Ainsi, il existe un unique réel $u_n\in[n,+\infty[$ tel
        que $f_n(u_n) = 1$.}~\\[-1.2cm]
      % 
    \end{proof}
  \end{noliste}

\item Étude de la suite $(u_n)$.
  \begin{noliste}{a)}
    \setlength{\itemsep}{2mm}
  \item Montrer que $\dlim{n \tend +\infty} u_n = +\infty$.

    \begin{proof}~\\
      Soit $n\in\N$.
      \begin{noliste}{$\sbullet$}
      \item Par définition de $u_n$, on sait que $u_n \in
        [n,+\infty[$. Ainsi, $u_n \geq n$.
      \item Or : $n \tendn +\infty$.
      \end{noliste}
      \conc{Par théorème de comparaison, $\dlim{n\to+\infty} u_n =
        +\infty$.}~\\[-1.2cm]
    \end{proof}

  \item Montrer que : $\forall n \in \N$, $\ee^{-\sqrt{u_n}} \leq
    u_n-n \leq \ee^{-\sqrt{n}}$.

    \begin{proof}~%
      \begin{noliste}{$\sbullet$}
      \item Soit $t \in [n, u_n]$. Remarquons tout d'abord :
        \[
        \begin{array}{rcl@{\quad}>{\it}R{5.5cm}}
          n \ \leq \ t \ \leq \ u_n & \Leftrightarrow & \sqrt{n} \
          \leq \ \sqrt{t} \ \leq \ \sqrt{u_n}
          & (car $t \mapsto \sqrt{t}$ est strictement \\ croissante sur $\R_+$)
          \nl
          \nl[-.2cm]
          & \Leftrightarrow & \ee^{\sqrt{n}} \ \leq \ \ee^{\sqrt{t}} \
          \leq \ \ee^{\sqrt{u_n}} & (car $t \mapsto \ee^t$ est 
          strictement \\ croissante sur $\R$) 
          \nl
        \end{array}
        \]
        \conc{$\forall t \in [n, u_n]$, \ $\ee^{\sqrt{n}} \ \leq \
          g(t) \ \leq \ \ee^{\sqrt{u_n}}$}~

      \item Par croissance de l'intégrale, les bornes étant dans
        l'ordre croissant ($u_n \geq n$) :
        \[
        \begin{array}{ccccc}
          \dint{n}{u_n} \ee^{\sqrt{n}} \dt & \leq & \dint{n}{u_n}
          \ee^{\sqrt{t}} \dt & \leq & \dint{n}{u_n} \ee^{\sqrt{u_n}} \dt 
          \\[.4cm]
          \shortparallel & & \shortparallel & & \shortparallel
          \\[.2cm]
          \ee^{\sqrt{n}} \ (u_n - n) & \leq & f_n(u_n) & \leq &
          \ee^{\sqrt{u_n}} \ (u_n - n)  
          \\[.4cm]
          & & \shortparallel & & 
          \\[.2cm]
          & & 1 & & 
        \end{array}
        \]

      \item Ainsi : $\ee^{\sqrt{n}} \ (u_n - n) \leq 1$.%
        \conc{Par multiplication par $\ee^{-\sqrt{n}} \geq 0$, on
          obtient : $u_n - n \leq \ee^{-\sqrt{n}}$}

      \item Et : $1 \leq \ee^{\sqrt{u_n}} \ (u_n - n)$.%
        \conc{Par multiplication par $\ee^{-\sqrt{u_n}} \geq 0$, on
          obtient : $\ee^{-\sqrt{u_n}} \leq u_n - n$}~\\[-1.4cm]
      \end{noliste}
      % \conc{$\forall n\in\N$, $\ee^{-\sqrt{u_n}}\leq u_n -n \leq
      %   \ee^{-\sqrt{n}}$}~\\[-1.2cm]
    \end{proof}
  \end{noliste}

\item
  \begin{noliste}{a)}
    \setlength{\itemsep}{2mm}
  \item Utiliser la question \itbf{2.b)} pour compléter les commandes
    \Scilab{} suivantes afin qu'elles permettent d'afficher un entier
    naturel $n$ pour lequel $u_n-n$ est inférieur ou égal à $10^{-4}$.
    %%% ATTENTION COQUILLE ! C'était inscrit v_n dans l'énoncé
    %%% original (défini juste après...)
    \begin{scilab}
      & n = 0 \nl %
      & \tcFor{while} ------------ \nl %
      & \qquad n = ------------ \nl %
      & \tcFor{end} \nl %
      & disp(n)
    \end{scilab}


    %\newpage


    \begin{proof}~%\\
      \begin{noliste}{$\sbullet$}
      \item D'après ce qui précède : 
        \[
        \forall n \in \N, \ u_n - n \leq \ee^{-\sqrt{n}}
        \]

      \item Afin de trouver un entier $n$ tel que $u_n - n \leq
        10^{-4}$, il suffit de trouver $N \in \N$ tel que :
        \[
        \ee^{-\sqrt{N}} \leq 10^{-4}
        \]

      \item On obtient alors, par transitivité :
        \[
        u_N - N \leq \ee^{-\sqrt{N}} \leq 10^{-4}
        \]

      \item Il s'agit donc de trouver le premier entier $N$ tel que
        $\ee^{-\sqrt{N}} \leq 10^{-4}$.\\
        Pour ce faire, on teste successivement tous les entiers
        naturels.\\
        On arrête l'itération dès le premier entier qui satisfait
        cette relation.
        \begin{scilabC}{1}
          & \tcFor{while} exp(-sqrt(n)) > 10\puis{}(-4) \nl %
          & \qquad n = n + 1 \nl %
          & \tcFor{end} 
        \end{scilabC}
      \end{noliste}
      ~\\[-1.4cm]
    \end{proof}

  \item Le script affiche l'une des trois valeurs $n = 55$, $n = 70$
    et $n = 85$. \\
    Préciser laquelle en prenant $2,3$ comme valeur approchée de
    $\ln(10)$.

    \begin{proof}~
      \begin{noliste}{$\sbullet$}
      \item On cherche à déterminer l'entier $N$ précédent. Or :
        \[
        \begin{array}{rcl@{\quad}>{\it}R{5.5cm}}
          \ee^{-\sqrt{n}}\leq 10^{-4} & \Leftrightarrow & -\sqrt{n} 
          \leq \ln(10^{-4})=-4\ln(10) & (car $x\mapsto \ln(x)$ est 
          strictement croissante sur $\R_+^*$)
          \nl
          \nl[-.4cm]
          & \Leftrightarrow & \sqrt{n} \geq 4\ln(10)
          \\[.2cm]
          & \Leftrightarrow & n \geq \big( 4\ln(10) \big)^2 & (car
          $x\mapsto x^2$ est strictement croissante sur $[0,+\infty[$)
        \end{array}
        \]
        Ainsi, le premier entier vérifiant la relation :
        $\ee^{-\sqrt{n}} \leq 10^{-4}$ est l'entier $N = \big\lceil
        (4\ln(10))^2 \big\rceil$.\\
        {\it (où $x\mapsto \lceil x \rceil$ désigne la fonction partie
          entière par excès)}
      \item Cherchons maintenant une valeur approchée de
        $(4\ln(10))^2$.\\[.1cm]
        D'après l'énoncé : $\ln(10) \simeq 2,3$, donc $4\ln(10) \simeq
        9,2 \geq 9$.\\
        On en déduit :
        \[
        \big(4\ln(10) \big)^2 \geq 9^2 = 81
        \]  
        La seule solution possible parmi celles proposées est $n=85$.
      \end{noliste}
      \conc{Le script affiche $n=85$.}~\\[-1.2cm]
    \end{proof}    
  \end{noliste}


  %\newpage


\item On pose $v_n = u_n-n$.
  \begin{noliste}{a)}
    \setlength{\itemsep}{2mm}
  \item Montrer que $\dlim{n \tend +\infty} v_n= 0$.

    \begin{proof}~\\
      Soit $n\in\N$.
      \begin{noliste}{$\sbullet$}
      \item D'après la question \itbf{2.b)}, $\ee^{-\sqrt{u_n}} \leq
        u_n -n \leq \ee^{-\sqrt{n}}$. Autrement dit :
        \[
        \ee^{-\sqrt{u_n}} \leq v_n \leq \ee^{-\sqrt{n}}
        \]

      \item Or :
       \begin{noliste}{$\stimes$}
       \item $\dlim{n \tend +\infty} \ee^{-\sqrt{n}} = \dlim{u \tend
           +\infty} \ee^{-u} = 0$.\\[.1cm]
         En effet : $\dlim{n \tend +\infty} \sqrt{n} = +\infty$. 
       \item $\dlim{n \tend +\infty} \ee^{-\sqrt{u_n}} = \dlim{u \tend
           +\infty} \ee^{-u} = 0$.\\[.1cm]
         En effet, on rappelle que $\dlim{n \tend +\infty} u_n =
         +\infty$ (question \itbf{2.a)}) et donc : $\dlim{n \tend
           +\infty} \sqrt{u_n} = +\infty$.
       \end{noliste}
     \end{noliste}
     \conc{Par théorème d'encadrement, $\dlim{n\tend+\infty} 
     v_n=0$.}~\\[-1.2cm]
    \end{proof}

  \item Établir que, pour tout réel $x$ supérieur ou égal à $-1$, on a
    : $\sqrt{1 + x} \leq 1 + \dfrac{x}{2}$.

    \begin{proof}~%\\
      \begin{noliste}{$\sbullet$}
      \item Notons $h$ la fonction définie sur $[-1,+\infty[$ par :
        \[
        h(x) = \sqrt{1+x}
        \]

      \item La fonction $h$ est de classe $\Cont{2}$ sur
        $]-1,+\infty[$ et, pour tout $x\in \ ]-1,+\infty[$, on a :
        \[
        h'(x) = \dfrac{1}{2} \ (1+x)^{-\frac{1}{2}}
        % = \dfrac{1}{2\sqrt{1+x}}
        \quad \text{ et } \quad h''(x) = -\dfrac{1}{4} \
        (1+x)^{-\frac{3}{2}} = \dfrac{-1}{4} \
        \dfrac{1}{(1+x)^{\frac{3}{2}}} = \dfrac{-1}{4} \
        \dfrac{1}{(1+x) \ \sqrt{1+x}}
        \]
        Or : $1+x > 0$ et donc $\sqrt{1+x} > 0$. On en déduit :
        \[
        \forall x \in \ ]-1,+\infty[, \ h''(x)<0
        \]

      \item La fonction $h$ est donc concave.\\
        Sa courbe représentative est donc située en dessous de ses
        tangentes.\\
        En particulier, elle est située en dessous de sa tangente au
        point d'abscisse $0$. Ainsi :
        \[
        \forall x \in [-1,+\infty[, \ h(x) \ \leq \ h(0) + h'(0) \ (x-0)
        \]
        Enfin : $h(0) =\sqrt{1+0} = 1$ \quad et \quad $h'(0) =
        \dfrac{1}{2\sqrt{1+0}} = \dfrac{1}{2}$.%
        \conc{$\forall x\in[-1,+\infty[$, $\sqrt{1+x} \leq
          1 + \dfrac{x}{2}$}~\\[-1cm]
      \end{noliste}
      ~\\[-1.5cm]
    \end{proof}


    %\newpage


  \item Vérifier ensuite que : $\forall n \in \N^{*}$,
    $\ee^{-\sqrt{u_n}} \geq \ee^{-\sqrt{n}} \exp\left(
      -\dfrac{v_n}{2\sqrt{n}} \right)$.

    \begin{proof}~\\
      Soit $n\in\N^*$.
      \begin{noliste}{$\sbullet$}
      \item Remarquons tout d'abord :
        \[
        \begin{array}{rcl@{\quad}>{\it}R{5.5cm}}
          \ee^{-\sqrt{u_n}} \geq \ee^{-\sqrt{n}} \exp\left( 
            -\dfrac{v_n}{2\sqrt{n}}\right)
          & \Leftrightarrow & \ee^{-\sqrt{u_n}} \geq
          \exp\left(-\sqrt{n}-\dfrac{v_n}{2\sqrt{n}}\right) 
          \\[.4cm]
          & \Leftrightarrow & -\sqrt{u_n} \geq -\sqrt{n} - 
          \dfrac{v_n}{2\sqrt{n}} & (car $x \mapsto \ln(x)$ est
          strictement croissante sur $\R_+^*$) 
          \nl
          \nl[-.2cm]
          & \Leftrightarrow & \sqrt{u_n} \leq \sqrt{n} +
          \dfrac{v_n}{2\sqrt{n}}
          \\[.6cm]
          & \Leftrightarrow & \dfrac{\sqrt{u_n}}{\sqrt{n}} \leq 1+
          \dfrac{v_n}{2n} & (car $\sqrt{n} > 0$)
          \nl
          \nl[-.2cm]
          & \Leftrightarrow & \sqrt{\dfrac{u_n}{n}} \leq 1+ \dfrac{v_n}
          {2n}
          \\[.6cm]
          & \Leftrightarrow & \sqrt{\dfrac{v_n + n}{n}} \leq 1 +
          \dfrac{v_n}{2n}
          \\[.6cm]
          & \Leftrightarrow & \sqrt{1+\dfrac{v_n}{n}} \leq 1+ 
          \dfrac{\frac{v_n}{n}}{2}
        \end{array}
        \]        

      \item En appliquant le résultat de la question \itbf{4.b)} à $x
        = \dfrac{v_n}{n}$ (ce qui est licite car $\dfrac{v_n}{n} \geq
        0 >-1$), on démontre la dernière inégalité.\\
        Par raisonnement par équivalence, la première inégalité l'est
        alors aussi.
      \end{noliste}
      \conc{$\forall n\in\N^*$, \ $\ee^{-\sqrt{u_n}} \geq
        \ee^{-\sqrt{n}} \exp\left( -\dfrac{v_n}{2\sqrt{n}}
        \right)$} %~\\[-1cm]
      ~\\[-1.2cm]
    \end{proof}


    %\newpage


  \item Déduire de l'encadrement obtenu en \itbf{2.b)} que : $u_n - n
    \eqn{} \ee^{-\sqrt{n}}$.

    \begin{proof}~\\
      Soit $n\in\N^*$.
      \begin{noliste}{$\sbullet$}
      \item D'après la question \itbf{2.b)} :
        \[
        \begin{array}{rcccl@{\quad}>{\it}R{5cm}}
          \ee^{-\sqrt{n}} & \geq & u_n - n & \geq & \ee^{-\sqrt{u_n}}
          \\[.2cm]
          & & & \geq & \ee^{-\sqrt{n}}\exp\left(-\dfrac{v_n}{2\sqrt{n}}\right) 
          & (d'après la question \itbf{4.c)})
        \end{array}
        \]

      \item Comme $\ee^{-\sqrt{n}} > 0$, on obtient :
        \[
        1 \ \geq \ \dfrac{u_n - n}{\ee^{-\sqrt{n}}} \ \geq \ \exp\left(-
          \dfrac{v_n}{2\sqrt{n}}\right)
        \]

      \item Or, d'après la question \itbf{4.a)}, $\dlim{n \tend
          +\infty} v_n= 0$.\\
        On en déduit que $\dlim{n \tend +\infty}
        -\dfrac{v_n}{2\sqrt{n}} = 0$ et donc : $\dlim{n \tend
          +\infty} \exp\left(-\dfrac{v_n}{2\sqrt{n}}\right) = \ee^0 =
        1$.\\[.1cm]
        Ainsi, par théorème d'encadrement, $\dlim{n\tend+\infty}
        \dfrac{u_n-n} {\ee^{-\sqrt{n}}} = 1$.
      \end{noliste}
     \conc{$u_n-n \eqn \ee^{-\sqrt{n}}$}~\\[-1.2cm]
    \end{proof}
  \end{noliste}
\end{noliste}

\section*{Exercice 3}

\noindent 
\begin{noliste}{$\sbullet$}
\item Dans cet exercice, toutes les variables aléatoires sont
  supposées définies sur un même espace probabilisé $(\Omega, \A,
  \Prob)$. On désigne par $p$ un réel de $]0,1[$.
\item On considère deux variables aléatoires indépendantes $U$ et $V$,
  telles que $U$ suit la loi uniforme sur $[-3,1]$, et $V$ suit la loi
  uniforme sur $[-1,3]$.
\item On considère également une variable aléatoire $Z$, indépendante
  de $U$ et $V$, dont la loi est donnée par :
  \[
  \Prob(\Ev{Z = 1}) = p \quad \text{ et } \quad \Prob(\Ev{Z = -1}) =
  1-p
  \]
\item Enfin,on note $X$ la variable aléatoire, définie par :
  \[
  \forall \omega \in \Omega, \ X(\omega) = %
  \left\{
    \begin{array}{cR{2.4cm}}
      U(\omega) & si $Z(\omega) = 1$ 
      \nl
      \nl[-.2cm]
      V(\omega) & si $Z(\omega) = -1$
    \end{array}
  \right.
  \]
\item On note $F_X$, $F_U$ et $F_V$ les fonctions de répartition
  respectives des variables $X$, $U$ et $V$.
\end{noliste}

\begin{noliste}{1.}
  \setlength{\itemsep}{4mm}
\item Donner les expressions de $F_U(x)$ et $F_V(x)$ selon les valeurs
  de $x$.

  \begin{proof}~
    \begin{noliste}{$\sbullet$}
    \item D'après l'énoncé, $U \suit \Uc{-3}{1}$.\\ %
      \conc{Ainsi, pour tout $x\in\R$, $F_U(x) = %
        \left\{
          \begin{array}{c@{\quad}R{2.2cm}}
            0 & si $x<-3$
            \nl
            \nl[-.2cm]
            \dfrac{x+3}{4} & si $x\in[-3,1]$
            \nl
            \nl[-.2cm]
            1 & si $x>1$
          \end{array}
        \right.$.}


      %\newpage


    \item D'après l'énoncé, $V\suit \Uc{-1}{3}$. \\ %
      \conc{Ainsi, pour tout $x\in\R$, $F_V(x) = %
        \left\{
          \begin{array}{c@{\quad}R{2.2cm}}
            0 & si $x<-1$
            \nl
            \nl[-.2cm]
            \dfrac{x+1}{4} & si $x\in[-1,3]$
            \nl
            \nl[-.2cm]
            1 & si $x>3$
          \end{array}
        \right.$.}
    \end{noliste}
    ~\\[-1.4cm]
  \end{proof}

\item
  \begin{noliste}{a)}
    \setlength{\itemsep}{2mm}
  \item Établir, grâce au système complet d'évènements $\left( \Ev{Z =
        1}, \Ev{Z = -1} \right)$, que :
    \[
    \forall x\in\R, \ F_X(x) = p \ F_U(x) + (1-p) \ F_V(x)
    \]

    \begin{proof}~\\
      Soit $x \in \R$.\\
      La famille $\big(\Ev{Z = 1}, \Ev{Z = -1}\big)$ forme un système
      complet d'événements. \\
      Ainsi, d'après la formule des probabilités totales :
      \[
      \begin{array}{rcccc@{\quad}>{\it}R{4cm}}
        \Prob(\Ev{X\leq x}) & = & \Prob(\Ev{Z = 1} \cap \Ev{X\leq x})
        & + & \Prob(\Ev{Z = -1} \cap \Ev{X\leq x}) 
        \\[.2cm]
        & = & \Prob(\Ev{Z = 1} \cap \Ev{U \leq x}) & + & 
        \Prob(\Ev{Z = -1} \cap \Ev{V\leq x}) & (par définition de $X$)
        \nl
        \nl[-.2cm]
        & = & \Prob(\Ev{Z = 1}) \times \Prob(\Ev{U \leq x}) & + & 
        \Prob(\Ev{Z = -1}) \times \Prob(\Ev{V\leq x}) & (car $Z$ est
        indépendante de $U$ et de $V$) 
        \nl
        \nl[-.2cm]
        & = & p \times \Prob(\Ev{U \leq x}) & + & (1-p) \times 
        \Prob(\Ev{V\leq x}) \\[.2cm]
        & = & p \times F_U(x) & + & (1-p) \times F_V(x) 
      \end{array}
      \]
      \conc{Ainsi, pour tout $x \in \R$, \ $F_X(x) = p \ F_U(x) + (1-p)
        \ F_V(x)$.}~\\[-1cm]
    \end{proof}
    
  \item Vérifier que $X(\Omega) = [-3,3]$ puis expliciter $F_X(x)$
    dans les cas :
    \[
    x<-3, \quad -3\leq x\leq-1, \quad -1\leq x\leq1, \quad 1 \leq x
    \leq 3 \quad \text{ et } \quad x>3
    \]

    \begin{proof}~
      \begin{noliste}{$\sbullet$}
      \item Soit $\omega \in \Omega$. Deux cas se présentent.
        \begin{noliste}{$-$}
        \item \dashuline{Si $Z(\omega) = 1$} alors, par définition,
          $X(\omega) = U(\omega)$. \\
          Comme $U \suit \Uc{-3}{1}$ alors $U(\omega) \in [-3,1]$.\\[.1cm]
          Dans ce cas, $X(\omega)\in[-3,1]$.

        \item \dashuline{Si $Z(\omega) = -1$} alors, par définition,
          $X(\omega) = V(\omega)$.\\
          Comme $V \suit \Uc{-1}{3}$ alors $U(\omega) \in [-1,3]$.\\[.1cm]
          Dans ce cas, $X(\omega) \in [-1,3]$.
        \end{noliste}
        Ainsi, pour tout $\omega \in \Omega$, $X(\omega) \in [-3,1]
        \cup [-1,3] = [-3,3]$.%
        \conc{On en conclut : $X(\Omega) \subset [-3,3]$.}~\\[-1.2cm]
      \end{noliste}
      ~\\[-1.4cm]
      \begin{noliste}{$\sbullet$}
      \item Soit $x\in\R$. Plusieurs cas se présentent.
        \begin{noliste}{$-$}
        \item \dashuline{Si $x<-3$} alors $\Ev{X \leq x} =
          \emptyset$.\\[.1cm]
          On en déduit que \ $F_X(x) = \Prob(\Ev{X\leq x}) = 0$.
    
        \item \dashuline{Si $x\in[-3,-1]$} alors, d'après la question
          précédente : 
          \[
          F_X(x) \ = \ p \ F_U(x) + (1-p) \ F_V(x) \ = \ p
          \dfrac{x+3}{4} + (1-p) \times 0 \ = \ p \ \dfrac{x+3}{4}
          \]
          
        \item \dashuline{Si $x\in[-1,1]$} alors, d'après la question
          précédente : 
          \[
          F_X(x) \ = \ p \ F_U(x) + (1-p) \ F_V(x) \ = \ p \
          \dfrac{x+3}{4}+(1-p)\frac{x+1}{4} \ = \ \dfrac{x+2p+1}{4}
          \]
          
        \item \dashuline{Si $x \in [1,3]$} alors, d'après la question
          précédente :
          \[
          F_X(x) \ = \ p \ F_U(x) + (1-p) \ F_V(x) \ = \ p \times 1 +
          (1-p) \ \dfrac{x+1}{4} \ = \ p + (1-p) \ \dfrac{x+1}{4}
          \]
          
        \item \dashuline{Si $x>3$} alors $\Ev{X \leq x} =
          \Omega$.\\[.1cm]
          On en déduit que \ $F_X(x) = \Prob(\Ev{X\leq x}) = 1$.
        \end{noliste}%~\\[-2cm]        
        \conc{On en conclut que, pour tout $x\in\R$, \ $F_X(x) = %
          \left\{
            \begin{array}{c@{\quad}R{2.5cm}}
              0 & si $x<-3$ \nl
              \nl[-.2cm]
              p \ \dfrac{x+3}{4} & si $x\in[-3,-1]$ \nl
              \nl[-.2cm]
              \dfrac{x+2p+1}{4} & si $x\in[-1,1]$ \nl
              \nl[-.2cm]
              p + (1-p) \ \dfrac{x+1}{4} & si $x\in[1,3]$ \nl
              \nl[-.2cm]
              1 & si $x>3$
            \end{array}
          \right.$}~\\[-1.4cm]
      \end{noliste}
    \end{proof}


    %\newpage

    
  \item On admet que X est une variable à densité. Donner une densité
    $f_{X}$ de la variable aléatoire $X$.

    \begin{proof}~
      \begin{noliste}{$\sbullet$}
      \item La fonction $F_X$ est :
        \begin{noliste}{$\stimes$}
        \item continue sur $\R$.\\
          En effet, elle est de classe $\Cont{0}$ (même
          $\Cont{\infty}$) sur $]-\infty, -3[ \ \cup \ ]-3, -1[ \ \cup
          \ ]-1, 1[ \ \cup \ ]1, 3[ \ \cup \ ]3, +\infty[$ car
          polynomiale sur chacun de ces intervalles.\\
          De plus, elle est continue en $-3$ car : $\dlim{x \tend
            (-3)^-} F_X(x) = F_X(-3) = \dlim{x \tend (-3)^+} F_X(x) = 0$.\\
          De la même manière, elle est aussi continue en $-1$, $1$ et
          $3$.
        \item de classe $\Cont{1}$ sur $]-\infty, -3[ \ \cup \ ]-3,
          -1[ \ \cup \ ]-1, 1[ \ \cup \ ]1, 3[ \ \cup \ ]3, +\infty[ \
          = \R \setminus \{-3, -1, 1, 3\}$.
        \end{noliste}
        Ainsi, $X$ est une variable à densité.

      \item Afin d'obtenir une densité $f_X$, on dérive $F_X$ sur les
        intervalles {\bf ouverts}.\\
        Soit $x\in \R$. Plusieurs cas se présentent :
        \begin{noliste}{$\stimes$}
        \item \dashuline{si $x \in \ ]-\infty,-3[$} alors $f_X(x) =
          F_X'(x) = 0$.
        \item \dashuline{si $x\in \ ]-3,-1[$} alors $f_X(x) = F_X'(x) =
          \dfrac{p}{4}$.
        \item \dashuline{si $x\in \ ]-1,1[$} alors $f_X(x) = F_X'(x) =
          \dfrac{1}{4}$.
        \item \dashuline{si $x\in \ ]1,3[$} alors $f_X(x) = F_X'(x) =
          \dfrac{1-p}{4}$.
        \item \dashuline{si $x\in \ ]3,+\infty[$} alors $f_X(x) =
          F_X'(x) = 0$.  
        \end{noliste}	
        Enfin, on {\bf choisit}, par exemple, $f_X(-3) = 0$, $f_X(-1)
        = \dfrac{1}{4}$, $f_X(1) = \dfrac{1}{4}$ et $f_X(3) = 0$.
      \end{noliste}
      \conc{Ainsi, pour tout $x\in\R$, \ $f_X(x) = \left\{
          \begin{array}{c@{\quad}R{3cm}}
            0 & si $x\leq -3$ \nl
            \nl[-.2cm]
            \dfrac{p}{4} & si $x \in \ ]-3,-1[$ \nl
            \nl[-.2cm]
            \dfrac{1}{4} & si $x \in[-1,1]$ \nl
            \nl[-.2cm]
            \dfrac{1-p}{4} & si $x \in \ ]1,3[$ \nl
            \nl[-.2cm]
            0 & si $x\geq 3$
          \end{array}
        \right.$}%~\\[-1.2cm]
      ~\\[-1.2cm]
    \end{proof}	    

  \item Établir que $X$ admet une espérance $\E(X)$ et une variance
    $\V(X)$, puis les déterminer.

    \begin{proof}~
      \begin{noliste}{$\sbullet$}
      \item La \var $X$ admet une espérance si et seulement si
        l'intégrale impropre $\dint{-\infty}{+\infty} t \ f_X(t) \dt$
        est absolument convergente, ce qui équivaut à démontrer la
        convergence pour les calculs de moment du type
        $\dint{-\infty}{+\infty} t^n \ f_X(t) \dt$.
      \item Remarquons tout d'abord :
        \[
        \dint{-\infty}{+\infty} t \ f_X(t) \dt \ = \ \dint{-3}{3} t \
        f_X(t) \dt
        \]
        car $f$ est nulle en dehors de $[-3, 3]$.

      \item La fonction $t \mapsto t \ f(t)$ est {\bf continue par
          morceaux} sur $[-3, 3]$.\\
        On en déduit que $\dint{-3}{3} t \ f_X(t) \dt$ est bien
        définie et que $X$ admet une espérance donnée par :
        \[
        \begin{array}{rcl}
          \E(X) %\\[.2cm]
          & = & \dint{-\infty}{+\infty} t \ f_X(t) \dt \\[.6cm]
          & = & \bcancel{\dint{-\infty}{-3} t \ 0 \dt} +
          \dint{-3}{-1}t\ \dfrac{p}{4}\dt + \dint{-1}{1}t\
          \dfrac{1}{4}\dt + \dint{1}{3}t\ \dfrac{1-p}{4}\dt +
          \bcancel{\dint{3}{+\infty} t \ 0 \dt} \\[.6cm]
          & = & \dfrac{p}{4}\left[ \dfrac{t^2}{2} \right]_{-3}^{-1}
          +\dfrac{1}{4}\left[ \dfrac{t^2}{2} \right]_{-1}^{1}
          +\dfrac{1-p}{4}\left[ \dfrac{t^2}{2} \right]_{1}^{3}
          \\[.6cm]
          & = & \dfrac{p}{8} \ ((-1)^2 - (-3)^2) + \dfrac{1}{8} \
          (1^2 - (-1)^2) + \dfrac{1-p}{8} \ (3^2 - 1^2) \\[.4cm]
          & = & \dfrac{p}{8} \ (1 - 9) + \dfrac{1}{8} \
          \bcancel{(1 - 1)} + \dfrac{1-p}{8} \ (9 - 1) 
          \\[.4cm]
          & = & \dfrac{1}{8} \ (-8 \ p + 8 \ (1-p))
          \\[.4cm]
          & = & -p + (1-p) \ = \ 1-2p
        \end{array}
        \]
        
      \item De même, la fonction $t \mapsto t^2 \ f(t)$ est {\bf
          continue par morceaux} sur $[-3, 3]$. On en déduit que
        $\dint{-3}{3} t^2 \ f_X(t) \dt$ est bien définie et que $X$
        admet un moment d'ordre $2$ donné par :
        \[
        \begin{array}{rcl}
          \E(X^2) 
          & = & \dint{-\infty}{+\infty} t^2 f_X(t)\dt \\[.6cm]
          & = & \bcancel{\dint{-\infty}{-3} t^2 \ 0 \dt} +
          \dint{-3}{-1}t^2\ \dfrac{p}{4}\dt +
          \dint{-1}{1}t^2\ \dfrac{1}{4}\dt + \dint{1}{3}t^2\
          \dfrac{1-p}{4}\dt + \bcancel{\dint{3}{+\infty} t^2 \ 0
            \dt} \\[.6cm]
          & = & \dfrac{p}{4}\left[ \dfrac{t^3}{3} \right]_{-3}^{-1}
          +\dfrac{1}{4}\left[ \dfrac{t^3}{3} \right]_{-1}^{1}
          +\dfrac{1-p}{4}\left[ \dfrac{t^3}{3} \right]_{1}^{3}  \\[.6cm]
          & = & \dfrac{p}{12} \ ((-1)^3 - (-3)^3) + \dfrac{1}{12} \
          (1^3 - (-1)^3) + \dfrac{1-p}{12} \ (3^3 - 1^3) \\[.4cm]
          & = & \dfrac{p}{12} \ (-1 + 27) + \dfrac{1}{12} \
          (1 + 1) + \dfrac{1-p}{12} \ (27 - 1) 
          \ = \ \dfrac{1}{12} \ (26 \ p + 2 + 26 \ (1-p))
          \\[.4cm]
          & = & \dfrac{1}{6} \ (13 \ p + 1 + 13 \ (1-p)) \ = \
          \dfrac{1}{6} \ (\bcancel{13 \ p} + 1 + 13 - \bcancel{13 \ p}) \ = \
          \dfrac{14}{6} \ = \ \dfrac{7}{3}
        \end{array}
        \]
     
      \item Enfin, d'après la formule de K\oe{}nig-Huygens :
        \[
        \V(X) = \E(X^2) - (\E(X))^2 = \dfrac{7}{3}-(1-2p)^2 =
        \dfrac{7}{3} - (1 - 4p + 4p^2) = \dfrac{4}{3} + 4p - 4p^2
        \]
      \end{noliste}
      \conc{Ainsi, $\E(X) = 1-2p$ \ et \ $\V(X) = \dfrac{4}{3} + 4p -
        4p^2$.}%~\\[-1.2cm]


      %\newpage


      ~\\[-1.2cm]
%     \begin{center}
%         %\shorthandoff{;}  
%         \begin{tikzpicture}
%           [ xscale=2.5, yscale = 1, scale = .5, declare function =
%           {myfunc(\x) = (\x-3)*(\x-5)^2*(\x-2)+2.3;}, ] %
%           \draw[-] (2,0) -- (5.7,0); %
%           \draw[-] (2,7) -- (2,-.8) node[below] {$a_0 = a$}; %
%           \draw[-] (3.8,0) -- (3.8,-.8) node[below] {$a_1$}; %
%           \draw[-] (4.5,0) -- (4.5,-.8) node[below] {$a_2$}; %
%           \draw[-] (5.7,7) -- (5.7,-.8) node[below] {$a_3 = b$}; %
%           \filldraw[draw=black, fill=gray!20] (2,0) -- (2, 5.2) plot
%           [domain=2:3.8] (\x, {myfunc(\x)+2.2}) -- (3.8, 0) --
%           (2,0); %
%           \filldraw[draw=black, fill=gray!20] (3.8,0) -- (3.8, 3.8)
%           plot [domain=3.8:4.5] (\x, \x) -- (4.5, 0) -- (3.8,0); %
%           \filldraw[draw=black, fill=gray!20] (4.5,0) -- (4.5,
%           {myfunc(4.5)-1.5}) plot [domain=4.5:5.7] (\x,
%           {myfunc(\x)-1.5}) -- (5.7, 0) -- (4.5,0); %
%           \draw[very thick, red, domain = 2:3.8, samples = 100] plot
%           (\x, {myfunc(\x)+2.2}) node[above] {}; %
%           \draw[very thick, red, domain = 3.8:4.5, samples = 2] plot
%           (\x, {\x}) node[above] {}; %
%           \draw[very thick, red, domain = 4.5:5.7, samples = 100] plot
%           (\x, {myfunc(\x)-1.5}) node[above] {}; %
%           % -- cycle;
%         \end{tikzpicture}
%     \end{center}~\\[-2.2cm]
    \end{proof}    
  \end{noliste}


  
\item On se propose de montrer d'une autre façon que $X$ possède une
  espérance et un moment d'ordre $2$ puis de les déterminer.

  \begin{noliste}{a)}
    \setlength{\itemsep}{2mm}
  \item Vérifier que l'on a :
    \[
    X = U \ \dfrac{1 + Z}{2} + V \ \dfrac{1-Z}{2}
    \]    

    \begin{proof}~\\
      Soit $\omega \in \Omega$. Deux cas se présentent.
      \begin{noliste}{$\sbullet$}
      \item \dashuline{Si $Z(\omega) = 1$} alors $X(\omega) =
        U(\omega)$ et :
        \[
        U(\omega) \ \dfrac{1+Z(\omega)}{2} + V(\omega) \
        \dfrac{1-Z(\omega)}{2} = U(\omega) \ \dfrac{1+1}{2} +
        \bcancel{V(\omega) \ \dfrac{1-1}{2}} = U(\omega) = X(\omega)
        \]
      \item \dashuline{Si $Z(\omega) \neq 1$} alors $Z(\omega) = -1$,
        $X(\omega) = V(\omega)$ et :
        \[
        U(\omega) \ \dfrac{1+Z(\omega)}{2} + V(\omega) \
        \dfrac{1-Z(\omega)}{2} = \bcancel{U(\omega) \ \dfrac{1-1}{2}}
        + V(\omega) \ \dfrac{1+1}{2} = V(\omega) = X(\omega)
        \]    
      \end{noliste}
      \conc{Ainsi, pour tout $\omega \in \Omega$, \ $X(\omega) =
        U(\omega) \ \dfrac{1+Z(\omega)}{2} + V(\omega) \
        \dfrac{1-Z(\omega)}{2}$.}~\\[-1cm]
    \end{proof}


    %\newpage


  \item Déduire de l'égalité précédente que $X$ possède une espérance
    et retrouver la valeur de $\E(X)$.

    \begin{proof}~
      \begin{noliste}{$\sbullet$}
      \item Notons tout d'abord que $U$ et $V$ admettent une espérance
        car elles suivent des lois uniformes. \\
        De plus :
        \[
        \E(U) = \dfrac{-3 + 1}{2} = -1 \quad \text{ et } \quad \E(V) =
        \dfrac{-1 + 3}{2} = 1
        \]
      \item Les \var $Z$, $\dfrac{1+Z}{2}$ et $\dfrac{1-Z}{2}$ sont
        finies donc admettent une espérance. De plus :
        \[
        \E(Z) = \Sum{z \in Z(\Omega)}{} z \ \Prob(\Ev{Z = z}) = -1 \
        \Prob(\Ev{Z = -1}) + 1 \ \Prob(\Ev{Z = 1}) = -(1-p) + p = 2p-1
        \]
        Et par linéarité de l'espérance :
        \[
        \E\left(\dfrac{1+Z}{2}\right) = \dfrac{1}{2} \ (\E(1) + \E(Z)) =
        \dfrac{1}{2} \ (\bcancel{1} + 2p -\bcancel{1}) = p
        \]
        \[
        \E\left(\dfrac{1-Z}{2}\right) = \dfrac{1}{2} \ (\E(1) - \E(Z)) =
        \dfrac{1}{2} \ (1 - 2p + 1) = 1-p
        \]

      \item Les \var $U$ et $Z$ sont indépendantes.\\
        Par le lemme des coalitions, on en déduit que les \var $U$ et
        $\dfrac{1+Z}{2}$ sont indépendantes.\\
        On en déduit que la \var $U \ \dfrac{1+Z}{2}$ admet une
        espérance comme produit de \var indépendantes admettant une
        espérance. De plus : 
        \[
        \E\left(U \ \dfrac{1+Z}{2}\right) \ = \ \E(U) \
        \E\left(\dfrac{1+Z}{2}\right) = - p
        \]

      \item De même, les \var $V$ et $Z$ sont indépendantes.\\
        Par le lemme des coalitions, on en déduit que les \var $V$ et
        $\dfrac{1-Z}{2}$ sont indépendantes.\\
        On en déduit que la \var $V \ \dfrac{1-Z}{2}$ admet une
        espérance comme produit de \var indépendantes admettant une
        espérance. De plus : 
        \[
        \E\left(V \ \dfrac{1-Z}{2}\right) \ = \ \E(V) \
        \E\left(\dfrac{1-Z}{2}\right) = 1-p
        \]

      \item Enfin, d'après la question précédente, $X$ s'écrit comme
        la somme de deux \var qui admettent une espérance. On en
        déduit que $X$ admet une espérance. Par linéarité, on obtient
        :
        \[
        \begin{array}{rcl}
          \E(X) & = & \E\left(U \ \dfrac{1+Z}{2} + V \ \dfrac{1-Z}{2}
          \right)  
          \\[.6cm]
          & = & \E\left(U \ \dfrac{1+Z}{2}\right) + \E\left(V \
            \dfrac{1-Z}{2}\right) 
          \\[.6cm]
          & = & - p + (1-p) = 1-2p
        \end{array}
        \]
      \end{noliste}
      \conc{On retrouve bien que $X$ admet une espérance et que $\E(X)
        = 1-2p$.}~\\[-1.2cm]
    \end{proof}	    


    %\newpage


  \item En déduire également que $X$ possède un moment d'ordre $2$ et
    retrouver la valeur de $\E(X^{2})$.

    \begin{proof}~\\
      On procède comme dans la question précédente.
      \begin{noliste}{$\sbullet$}
      \item Tout d'abord :
        \[
        \begin{array}{rcl}
          X^2 & = & \left( U \ \dfrac{1+Z}{2} + V \ \dfrac{1-Z}{2} \right)^2
          = \left( U \ \dfrac{1+Z}{2} \right)^2 + UV \ \dfrac{1 -
            Z^2}{4} + \left( V \ \dfrac{1-Z}{2} \right)^2 \\[.6cm]
          & = & U^2 \ \dfrac{1 + 2Z + Z^2}{4} + UV \ \dfrac{1 -
            Z^2}{4} + V^2 \ \dfrac{1 - 2Z + Z^2}{4} 
        \end{array}
        \]
        Or, comme $Z(\Omega) = \{-1, 1\}$, $Z^2(\Omega) = \{1\}$ et
        ainsi $Z^2 = 1$ ($Z^2$ est la variable constante égale à $1$).
        On en déduit :
        \[
        \begin{array}{rcl}
          X^2 & = & U^2 \ \dfrac{1 + 2Z + 1}{4} + \bcancel{UV \ \dfrac{1 -
              1}{4}} + V^2 \ \dfrac{1 - 2Z + 1}{4} \\[.6cm]
          & = & U^2 \ \dfrac{1 + Z}{2} + V^2 \ \dfrac{1 - Z}{2}
        \end{array}
        \]

      \item Les \var $U$ et $V$, qui suivent des lois uniformes,
        admettent un moment d'ordre $2$ puisqu'elles admmettent une
        variance. On peut déduire de la formule de K\oe{}nig-Huygens :
        \[
        \E(U^2) = \V(U) + (\E(U))^2 = \dfrac{(1-(-3))^2}{12} + (-1)^2
        = \dfrac{16}{12} + 1 = \dfrac{4}{3} + 1 = \dfrac{7}{3}
        \]
        \[
        \E(V^2) = \V(V) + (\E(V))^2 = \dfrac{(3-(-1))^2}{12} + 1^2 =
        \dfrac{16}{12} + 1 = \dfrac{7}{3}
        \]

      \item Les \var $U^2$, $\dfrac{1 + Z}{2}$ admettent une espérance
        et sont indépendantes.\\
        On en déduit que la \var produit $U^2 \ \dfrac{1 + Z}{2}$
        admet une espérance, donnée par :
        \[
        \E\left( U^2 \ \dfrac{1 + Z}{2} \right) = \E(U^2) \
        \E\left(\dfrac{1 + Z}{2}\right) = \dfrac{7}{3} \ p
        \]

      \item Les \var $V^2$, $\dfrac{1 - Z}{2}$ admettent une espérance
        et sont indépendantes. \\
        On en déduit que la \var produit $V^2 \ \dfrac{1 - Z}{2}$
        admet une espérance, donnée par :
        \[
        \E\left( V^2 \ \dfrac{1 - Z}{2} \right) = \E(V^2) \
        \E\left(\dfrac{1 - Z}{2} \right) = \dfrac{7}{3} \ (1-p)
        \]

      \item $X^2$ admet une espérance car est la somme de \var qui
        admettent une espérance.\\
        Enfin, par linéarité de l'espérance :
        \[
        \begin{array}{rcl}
          \E(X^2) & = & \E\left(U^2 \ \dfrac{1 + Z}{2} + V^2 \ \dfrac{1 -
              Z}{2}\right) = \E\left(U^2 \ \dfrac{1 + Z}{2}\right) +
          \E\left(V^2 \ \dfrac{1 - Z}{2}\right) \\[.6cm]
          & = & \dfrac{7}{3} \ p + \dfrac{7}{3} \ (1-p) = \dfrac{7}{3}
          \ (p+(1-p)) = \dfrac{7}{3}
        \end{array}
        \]        
      \end{noliste}
      \conc{La \var $X$ admet un moment d'ordre $2$ et $\E(X^2) =
        \dfrac{7}{3}$.}~\\[-1.2cm]
    \end{proof}

\end{noliste}

\item
  \begin{noliste}{a)}
    \setlength{\itemsep}{2mm}
  \item Soit $T$ une variable aléatoire suivant la loi de Bernoulli de
    paramètre $p$.\\
    Déterminer la loi de $2T-1$.

    \begin{proof}~
      \begin{noliste}{$\sbullet$}
      \item Comme $T \suit \Bern{p}$, $T(\Omega) = \{0,
        1\}$. On en déduit :
        \[
        \begin{array}{rcl}
          (2T-1)(\Omega) & = & \{ 2 u - 1 \ | \ u \in T(\Omega) \} 
          \\[.2cm]
          & = & \{2 \times (-1) - 1, 2 \times - 1\} 
          \\[.2cm]
          & = & \{-1, 1\}
        \end{array}
        \]
        \conc{$(2T-1)(\Omega) = \{-1, 1\}$}

      \item De plus :
        \[
        \begin{array}{lcl}
          \Prob(\Ev{2T-1 = -1}) & = & \Prob(\Ev{2T = 0}) \ = \ \Prob(\Ev{T = 0})
          \ = \ 1 - p \\[.4cm]
          \Prob(\Ev{2T-1 = 1}) & = & \Prob(\Ev{2T = 2}) \ = \ \Prob(\Ev{T = 1})
          \ = \ p
        \end{array}
        \]
      \end{noliste}
      \conc{Ainsi, $2T-1$ et $Z$ suivent la même loi.}
      ~\\[-1.4cm]
    \end{proof}

  \item On rappelle que {\tt grand(1,1,\ttq{}unf\ttq{},a,b)} et {\tt
      grand(1,1,\ttq{}bin\ttq{},p)} sont des commandes \Scilab{}
    permettant de simuler respectivement une variable aléatoire à
    densité suivant la loi uniforme sur $[a,b]$ et une variable
    aléatoire suivant la loi de Bernoulli de paramètre $p$.\\
    Écrire des commandes \Scilab{} permettant de simuler $U$, $V$,
    $Z$, puis $X$.

    \begin{proof}~%
      \begin{noliste}{$\sbullet$}
      \item Pour simuler les \var $U$, $V$ et $T$, il suffit
        d'utiliser les instructions données.
        \begin{scilab}
          & U = grand(1,1,\ttq{}unf\ttq{},-3,1) \nl %
          & V = grand(1,1,\ttq{}unf\ttq{},-1,3) \nl %
          & T = grand(1,1,\ttq{}bin\ttq{},p) 
        \end{scilab}~

      \item Pour les \var $Z$ et $X$ on utilise les questions
        \itbf{3.a)} et \itbf{4.a)}.
        \begin{scilabC}{3}
          & Z = 2 \Sfois{} T - 1 \nl %
          & X = U \Sfois{} (1+Z)/2 + V \Sfois{} (1-Z)/2
        \end{scilabC}
      \end{noliste}


      %\newpage


      ~\\[-1.2cm]
    \end{proof}
  \end{noliste}
\end{noliste}

\section*{Problème}

\subsection*{Partie I : Questions préliminaires.}

\noindent
Dans cette partie, $x$ désigne un réel élément de $[0,1[$.
\begin{noliste}{1.}
  \setlength{\itemsep}{4mm}
\item
  \begin{noliste}{a)}
    \setlength{\itemsep}{2mm}
  \item Pour tout $n$ de $\N^*$ et pour tout $t$ de $[0,x]$,
    simplifier la somme $\Sum{p = 1}{n} t^{p-1}$.

    \begin{proof}~\\
      Soit $n \in \N^*$ et soit $t \in [0, x]$. Par conséquent, $t
      \leq x < 1$ et donc $t \neq 1$. Ainsi :
      \[
      \Sum{p = 1}{n} t^{p-1} \ = \ \Sum{p = 0}{n-1} t^p \ = \
      \dfrac{1-t^{n}}{1-t}
      \]
      \conc{$\forall n \in \N^*, \forall t \in [0,x], \ \Sum{p = 1}{n}
        t^{p-1} \ = \ \dfrac{1-t^{n}}{1-t}$}~\\[-1cm]
    \end{proof}


    %\newpage


  \item En déduire que : $\Sum{p = 1}{n}\dfrac{x^{p}}{p} = - \ln(1-x)
    - \dint{0}{x} \dfrac{t^n}{1-t} \dt$.

    \begin{proof}~
      \begin{noliste}{$\sbullet$}
      \item La fonction $t \mapsto \Sum{p = 1}{n} t^{p-1}$ (polynôme
        de degré $n-1$) est continue sur $[0, x]$. Il en est donc de
        même de la fonction $t \mapsto \dfrac{1-t^n}{1-t}$ puisque ces
        deux fonctions coïncident sur $[0, x]$.

      \item On déduit de la question précédente :
        \[
        \begin{array}{rcl>{\it}R{4cm}}
          \dint{0}{x} \left(\Sum{p = 1}{n} t^{p-1}\right) \dt & = &
          \dint{0}{x} \dfrac{1-t^n}{1-t} \dt 
          \ = \ \dint{0}{x} \dfrac{1}{1-t} \dt - \dint{0}{x}
          \dfrac{t^n}{1-t} \dt 
          & (par linéarité \\ de l'intégration)
          \nl
          \nl[-.2cm]
          & = & - \dint{0}{x} \dfrac{-1}{1-t} \dt - \dint{0}{x}
          \dfrac{t^n}{1-t} \dt \\[.6cm]
          & = & - \Prim{\ln(|1-t|)}{0}{x} - \dint{0}{x}
          \dfrac{t^n}{1-t} \dt \\[.6cm]
          & = & - \Prim{\ln(1-t)}{0}{x} - \dint{0}{x}
          \dfrac{t^n}{1-t} \dt & (car $1-t > 0$ \\ puisque $t < 1$) \nl
          \nl[-.2cm]
          & = & - (\ln(1-x) - \bcancel{\ln(1)}) - \dint{0}{x}
          \dfrac{t^n}{1-t} \dt
        \end{array}
        \]
        On remarque enfin, par linéarité de l'intégration :
        \[
        \dint{0}{x} \left(\Sum{p = 1}{n} t^{p-1}\right) \dt = \Sum{p =
          1}{n} \dint{0}{x} t^{p-1} \dt = \Sum{p = 1}{n}
        \Prim{\dfrac{t^{p}}{p}}{0}{x} = \Sum{p = 1}{n} \dfrac{x^p}{p}
        \]
      \end{noliste}
      \conc{$\forall x \in [0,1[$, $\forall n \in \N^*$, $\Sum{p =
          1}{n} \dfrac{x^{p}}{p} = - \ln(1-x) - \dint{0}{x}
        \dfrac{t^{n}}{1-t} \dt$}~\\[-1cm]
    \end{proof}

  \item Établir par encadrement que l'on a : $\dlim{n \tend +\infty}
    \dint{0}{x} \dfrac{t^n}{1-t} \dt = 0$.
    \begin{proof}~\\
      Soit $t \in [0, x]$. Ce qui signifie que $0 \leq t \leq x$.
      \begin{noliste}{$\sbullet$}
      \item Tout d'abord, par croissance de la fonction élévation à la
        puissance $n$ sur $\R_+$ : 
        \[
        0 \leq t^n \leq x^n
        \]

      \item D'autre part :
        \[
        \begin{array}{C{2cm}l@{\qquad}>{\it}R{5cm}}
          comme & 0 \leq t \leq x \\[.2cm]
          alors & 0 \geq -t \geq -x \\[.2cm]
          et & 1 \geq 1-t \geq 1-x \\[.2cm]
          enfin & 1 \leq \dfrac{1}{1-t} \leq \dfrac{1}{1-x} & (par
          décroissance de \\ la fonction inverse sur $\R_{+}^*$)
        \end{array}
        \]
        
      \item Toutes les quantités étant positives, on déduit des deux
        précédentes inégalités :
        \[
        0 \leq \dfrac{t^n}{1-t} \leq \dfrac{x^n}{1-x}
        \]

      \item La fonction $t \mapsto \dfrac{t^n}{1-t}$ est continue sur
        $[0, x]$.\\
        Ainsi, par croissance de l'intégrale, les bornes étant dans
        l'ordre croissant ($0 \leq x$) :
        \[
        0 \leq \dint{0}{x} \dfrac{t^n}{1-t} \dt \leq \dint{0}{x}
        \dfrac{x^n}{1-x} \dt = \dfrac{x^n}{1-x} \ \dint{0}{x} 1 \dt =
        \dfrac{x^{n+1}}{1-x}
        \]

      \item Or :
        \begin{noliste}{$\stimes$}
        \item $\dlim{n \tend +\infty} 0 = 0$,
        \item $\dlim{n \tend +\infty} \dfrac{x^{n+1}}{1-x} = 0$ car,
          comme $x \in [0, 1[$, $x^{n+1} \tendn 0$.
        \end{noliste}
        On en déduit donc, par théorème d'encadrement, que
        $\dint{0}{x} \dfrac{t^n}{1-t} \dt$ admet une limite lorsque
        $n$ tend vers $+\infty$, et que cette limite est nulle.
      \end{noliste}
      \conc{$\forall x \in [0,1[$, $\dlim{n \tend +\infty} \dint{0}{x}
        \dfrac{t^n}{1-t} \dt = 0$}%~\\[-1cm]
      ~\\[-1.4cm]
    \end{proof}

  \item En déduire que : $\Sum{k = 1}{+ \infty}\dfrac{x^k}{k} =
    -\ln(1-x)$.

    \begin{proof}~\\
      Soit $x \in [0, 1[$ et $n \in \N^*$
      \begin{noliste}{$\sbullet$}
      \item D'après la question \itbf{1.b)}, $\Sum{p = 1}{n}
        \dfrac{x^{p}}{p}$ admet une limite finie lorsque $n \tend
        +\infty$ car s'écrit comme la somme de deux quantités ayant
        une limite finie.

      \item Par passage à la limite, on en déduit :
        \[
        \begin{array}{ccccc}
          \Sum{p = 1}{n} \dfrac{x^{p}}{p} & = & - \ln(1-x) & - &
          \dint{0}{x} \dfrac{t^{n}}{1-t} \dt 
          \\[.2cm]
          \rotatebox{-90}{$\tendn$} & & \rotatebox{-90}{$\tendn$} & &
          \rotatebox{-90}{$\tendn$} 
          \\[1.2cm]
          \Sum{p = 1}{+\infty} \dfrac{x^{p}}{p} & = & - \ln(1-x) & - &
          0
        \end{array}
        \]

      \end{noliste}
      \conc{On en déduit : $\Sum{p = 1}{+\infty} \dfrac{x^{p}}{p}
        = -\ln(1-x)$.}~\\[-1cm]
    \end{proof}

  \end{noliste}


  %\newpage


\item Soit $m$ un entier naturel fixé. À l'aide de la formule du
  triangle de Pascal, établir l'égalité :
  \[
  \forall q \geq m, \ \Sum{k = m}{q} \dbinom{k}{m} = \dbinom{q + 1}{m
    + 1}
  \]

  \begin{proof}~\\
    L'entier $m$ étant fixé, démontrons par récurrence : $\forall
    q \geq m$, $\PP{q}$ \\
    où $\PP{q}$ : $\Sum{k=m}{q} \dbinom{k}{m} = \dbinom{q+1}{m+1}$.
    \begin{noliste}{1)}
    \item {\bf Initialisation} :
      \begin{noliste}{$\sbullet$}
      \item D'une part : $\Sum{k=m}{m} \dbinom{k}{m} = \dbinom{m}{m} =
        1$.
      \item D'autre part : $\dbinom{m+1}{m+1} = 1$.        
      \end{noliste}
      D'où $\PP{m}$.
      
    \item {\bf Hérédité} : soit $q \geq m$.\\
      Supposons $\PP{q}$ et démontrons $\PP{q+1}$ (\ie $\Sum{k=m}{q+1}
      \dbinom{k}{m} = \dbinom{q+2}{m+1}$).\\
      Tout d'abord :
      \[
      \begin{array}{rcl@{\quad}>{\it}R{4cm}}
        \Sum{k=m}{q+1} \dbinom{k}{m} & = & \Sum{k=m}{q}
        \dbinom{k}{m} + \dbinom{q+1}{m} \\[.6cm]
        & = & \dbinom{q+1}{m+1} + \dbinom{q+1}{m} & (par hypothèse \\ de
        récurrence) \nl
        \nl
        & = & \dbinom{q+2}{m+1} & (par la formule du \\ triangle de Pascal)
      \end{array}
      \]
      D'où $\PP{q+1}$.
    \end{noliste}
    \conc{Par principe de récurrence : $\forall q \geq m, \
      \PP{q}$.}~\\[-1.2cm] 
  \end{proof}
  
\item Soit $n$ un entier naturel non nul. On considère une suite
  $(X_n)_{n\in\N^{*}}$ de variables aléatoires, mutuellement
  indépendantes, suivant toutes la loi géométrique de paramètre $x$,
  et on pose $S_n = \Sum{k = 1}{n}X_k$.
  \begin{noliste}{a)}
    \setlength{\itemsep}{2mm}
  \item Déterminer $S_n(\Omega)$ puis établir que, pour tout entier
    $k$ supérieur ou égal à $n + 1$, on a :
    \[
    \Prob(\Ev{S_{n + 1} = k}) \ = \ \Sum{j = n}{k-1} \Prob(\Ev{S_n =
      j} \cap \Ev{X_{n + 1} = k-j})
    \]

    \begin{proof}~
      \begin{noliste}{$\sbullet$}
      \item Pour tout $k \in \N^*$, $X_k(\Omega) = \llb 1, +\infty
        \llb$. Ainsi, pour tout $\omega \in \Omega$ : 
        \[
        S_n(\omega) \ = \ \Sum{k=1}{n} X_k(\omega) \ \geq \
        \Sum{k=1}{n} 1 \ = \ n
        \]
        \conc{On en déduit : $S_n(\Omega) \subset \llb n, +\infty
          \llb$.}
      \end{noliste}

        %\newpage


      %~\\[-1.2cm]
      \begin{noliste}{$\sbullet$}        
      \item La famille $\big(\Ev{S_n = j}\big)_{j \in \llb n, +\infty
          \llb}$ forme un système complet d'événements.\\
        Soit $k \geq n+1$. Par la formule des probabilités totales :
        \[
        \begin{array}{rccl@{\quad}>{\it}R{4.5cm}}
          \Prob(\Ev{S_{n+1} = k}) & = & & \Sum{j=n}{+\infty}
          \Prob(\Ev{S_{n} = j} \ \cap \ \Ev{S_{n+1} = k}) 
          \\[.4cm]
          & = & & \Sum{j=n}{+\infty} \Prob(\Ev{S_{n} = j} \ \cap \
          \Ev{S_n + X_{n+1} = k}) 
          \\[.4cm] 
          & = & & \Sum{j=n}{+\infty} \Prob(\Ev{S_{n} = j} \ \cap \
          \Ev{X_{n+1} = k - j}) 
          \\[.4cm] 
          & = & & \Sum{%
            \scalebox{.8}{$
            \begin{array}{c}
              j=n \\
              k -j \in X_{n+1}(\Omega)
            \end{array}
            $}
          }{+\infty} \Prob(\Ev{S_{n} = j} \ \cap \ \Ev{X_{n+1} = k-j})
          \\[1cm]
          & &  + & \bcancel{\Sum{%
            \scalebox{.8}{$
            \begin{array}{c}
              j=n \\
              k -j \not\in X_{n+1}(\Omega)
            \end{array}
            $}}{+\infty} \Prob(\Ev{S_{n} = j} \ \cap \
            \Ev{X_{n+1} = k-j})} & (car $\Ev{X_{n+1} = k-j} = \emptyset$) 
          \nl
          \nl[-.2cm]
          & = & & \Sum{j=n}{k-1} \Prob(\Ev{S_{n} = j} \ \cap \
          \Ev{X_{n+1} = k-j})
        \end{array}
        \]
      \end{noliste}


      %\newpage


      \noindent
      La dernière ligne est obtenue en constatant :
      \[
      \left\{
        \begin{array}{l}
          k-j \in X_{n+1}(\Omega) = \N^* \\[.2cm]
          j \in \llb n, +\infty \llb
        \end{array}
      \right.
      \ \Leftrightarrow \
      \left\{
        \begin{array}{l}
          1 \leq k-j \\[.2cm]
          n \leq j
        \end{array}
      \right.
      \ \Leftrightarrow \
      \left\{
        \begin{array}{l}
          j \leq k-1 \\[.2cm]
          n \leq j
        \end{array}
      \right.
      \ \Leftrightarrow \
      \left\{
        \begin{array}{l}
          n \leq j \leq k-1
        \end{array}
      \right.
      \]
      \conc{$\forall k \geq n+1, \ \Prob(\Ev{S_{n+1} = k}) =
        \Sum{j=n}{k-1} \Prob(\Ev{S_{n} = j} \ \cap \ \Ev{X_{n+1} =
          k-j})$}%~\\[-1.4cm]
      ~\\[-1.4cm]
    \end{proof}

  \item En déduire, par récurrence sur $n$, que la loi de $S_n$ est
    donnée par :
    \[
    \forall k \in \llb n, + \infty \llb, \ \Prob(\Ev{S_n = k}) =
    \dbinom{k-1}{n-1} \ x^n \ (1-x)^{k-n}
    \]

    \begin{proof}~\\
      Démontrons par récurrence : $\forall n \in \N^*, \ \PP{n}$\\[.2cm]
      où $\PP{n}$ : $\forall k \in \llb n, +\infty \llb, \
      \Prob(\Ev{S_{n} = k}) = \dbinom{k-1}{n-1} \ x^{n} \
      (1-x)^{k-n}$.
      \begin{noliste}{1)}
      \item {\bf Initialisation} :\\
        Soit $k \in \llb 1, +\infty \llb$.
        \begin{noliste}{$\sbullet$}
        \item D'une part : $\Prob(\Ev{S_{1} = k}) = \Prob(\Ev{X_{1} =
            k}) = (1-x)^{k-1} \ x$ car $S_1 = X_1 \suit \G{x}$.

        \item D'autre part : $\dbinom{k-1}{1-1} \ x^{1} \ (1-x)^{k-1}
          = \dbinom{k-1}{0} \ x^{1} \ (1-x)^{k-1} = x \ (1-x)^{k-1}$.
        \end{noliste}
        D'où $\PP{1}$.

      \item {\bf Hérédité} : soit $n \in \N^*$.\\
        Supposons $\PP{n}$ et démontrons $\PP{n+1}$ \\[.2cm]
        (\ie $\forall k \in \llb n+1, +\infty \llb, \
        \Prob(\Ev{S_{n+1} = k}) = \binom{k-1}{n} \ x^{n+1} \
        (1-x)^{k-(n+1)}$).


        %\newpage


        \noindent
        Soit $k \in \llb n+1, +\infty \llb$.
        \[
        \begin{array}{cl@{\qquad}>{\it}R{5cm}}
          & \Prob(\Ev{S_{n+1} = k}) 
          \\[.2cm] 
          = & \Sum{j=n}{k-1} \Prob(\Ev{S_{n}
            = j} \ \cap \ \Ev{X_{n+1} = k-j}) 
          \\[.4cm]
          = & \Sum{j=n}{k-1} \Prob(\Ev{S_{n} = j}) \ \times \ 
          \Prob(\Ev{X_{n+1} = k-j}) & (car $S_n$ et $X_{n+1}$ \\ sont
          indépendantes (*)) 
          \nl
          \nl[-.2cm]
          = & \Sum{j=n}{k-1} \left(\dbinom{j-1}{n-1} \ x^{n} \
            (1-x)^{j-n} \right) \times \Prob(\Ev{X_{n+1} = k-j}) & (par
          hypothèse \\ de récurrence) 
          \nl
          \nl[-.2cm]
          = & \Sum{j=n}{k-1} \left(\dbinom{j-1}{n-1} \ x^{n} \
            (1-x)^{j-n} \right) \ (1-x)^{k-j-1} \ x & (car $X_{n+1}
          \suit \G{x}$) 
          \nl
          \nl[-.2cm]
          = & \Sum{j=n}{k-1} \dbinom{j-1}{n-1} \ x^{n+1} \
          (1-x)^{k-n-1} 
          \\[.4cm]
          = & (x^{n+1} \ (1-x)^{k-n-1}) \ \Sum{j=n}{k-1}
          \dbinom{j-1}{n-1} & (car $x^{n+1} \ (1-x)^{k-n-1}$ est
          indépendant de l'indice de sommation $j$) 
          \nl
          \nl[-.2cm]
          = & (x^{n+1} \ (1-x)^{k-n-1}) \ \Sum{j=n-1}{k-2}
          \dbinom{j}{n-1} 
          \\[.8cm]
          = & (x^{n+1} \ (1-x)^{k-n-1}) \ \dbinom{k-1}{n} & (d'après
          la question \itbf{2.} avec $q = k-2$, $m = n-1$) 
        \end{array}
        \]
        D'où $\PP{n+1}$.
      \end{noliste}~\\[-.3cm]
      (*) En effet, $X_{n+1}$ est indépendante de $X_1$, $X_2$,
      \ldots, $X_n$.\\
      On en déduit, par le lemme des coalitions, que $X_{n+1}$ est
      indépendante de $X_1 + \ldots + X_n$.%
      \conc{Par principe de récurrence : $\forall n \in \N^*, \
        \PP{n}$.}~\\[-1cm]
    \end{proof}

  \item En déduire, pour tout $x$ de $]0,1[$ et pour tout entier
    naturel $n$ non nul :
    \[
    \Sum{k = n}{+ \infty} \dbinom{k-1}{n-1} \ (1-x)^{k-n} =
    \dfrac{1}{x^n}
    \]

    \begin{proof}~\\
      Soit $x \in \ ]0,1[$ et soit $n \in \N^*$.\\
      La famille $\big(\Ev{S_n = k}\big)_{k \in \llb n, +\infty \llb}$
      forme un système complet d'événements.\\
      On en déduit :
      \[
      \begin{array}{cc@{\qquad}c>{\it}R{4cm}}
        \Sum{k = n}{+\infty} \ \Prob(\Ev{S_n = k}) & = & 1 \\[.2cm]
        \shortparallel & & \\[.2cm]
        \Sum{k = n}{+\infty} \dbinom{k-1}{n-1} \ x^n \ (1-x)^{k-n} & & &
        (d'après la \\ question précédente)
      \end{array}
      \]
      \concL{On en déduit, en multipliant de part et d'autre par
        $\dfrac{1}{x^n}$ : \\
        $\Sum{k = n}{+\infty} \dbinom{k-1}{n-1} \ (1-x)^{k-n} =
        \dfrac{1}{x^n}$}{12}~\\[-1cm]
    \end{proof}
      

    %\newpage


  \item On rappelle que la commande {\tt
      grand(1,n,\ttq{}geom\ttq{},p)} permet à \Scilab{} de simuler $n$
    variables aléatoires indépendantes suivant toutes la loi
    géométrique de paramètre $p$.\\
    Compléter les commandes \Scilab{} suivantes pour qu'elles simulent
    la variable aléatoire $S_n$.\\
    \begin{scilab}
      & n = input(\ttq{}entrez une valeur de n supérieure à 1 :\ttq{}) \nl %
      & S = ------------\nl %
      & disp(S)
    \end{scilab}

    \begin{proof}~%
      \begin{noliste}{$\sbullet$}
      \item On rappelle que $S_n = \Sum{k=1}{n} X_k$ où les \var
        $X_1$, \ldots, $X_n$ sont indépendantes et suivent toutes la
        même loi $\G{x}$. L'instruction {\tt
          grand(1,n,\ttq{}geom\ttq{},p)} permet de générer une matrice
        ligne $[x_1, \ldots, x_n]$ qui simule le $n$-échantillon
        $(X_1, \ldots, X_n)$.
      \item Pour simuler $S_n$, il suffit de faire la somme des
        coefficients de cette matrice ligne.
        \begin{scilabC}{1}
          & S = sum(grand(1,n,\ttq{}geom\ttq{},p)) \nl %
        \end{scilabC}
      \end{noliste}
      ~\\[-1.4cm]
    \end{proof}
  \end{noliste}
\end{noliste}

\subsection*{Partie 2 : étude d'une variable aléatoire.}

\noindent
Dans cette partie, on désigne par $p$ un réel de $]0,1[$ et on pose $q
= 1-p$.\\
On considère la suite $(u_k)_{k\in\N^{*}}$, définie par :
\[
\forall k\in\N^*, \ u_k = -\dfrac{q^{k}}{k \ \ln(p)}
\]
\begin{noliste}{1.}
  \setlength{\itemsep}{4mm}
\item
  \begin{noliste}{a)}
    \setlength{\itemsep}{2mm}
  \item Vérifier que la suite $(u_k)_{k\in\N^{*}}$ est à termes
    positifs.

    \begin{proof}~\\%
      Soit $k \in \N^*$.
      \begin{noliste}{$\sbullet$}
      \item Comme $p \in \ ]0, 1[$, $\ln(p) < 0$.
      \item Comme $q = 1-p \in \ ]0, 1[$, $q^k > 0$. On en déduit :
        \[
        \dfrac{q^k}{k \ \ln(p)} < 0
        \]
        {\it (notons que $k \times \ln(p) \neq 0$ car $k \geq 1$ et
          $\ln(p) \neq 0$)}
      \end{noliste}
      \conc{Ainsi, pour tout $k \in \N^*$, $u_k = -\dfrac{q^k}{k \
          \ln(p)} > 0$}~\\[-1cm]
    \end{proof}


    %\newpage


  \item Montrer, en utilisant un résultat de la partie $1$, que
    $\Sum{k = 1}{+ \infty} u_k = 1$.

    \begin{proof}~\\%
      Soit $N \in \N^*$.
      \begin{noliste}{$\sbullet$}
      \item Tout d'abord : $\Sum{k=1}{N} u_k \ = \ \Sum{k=1}{N}
        \dfrac{-q^k}{k \ \ln(p)} \ = \ -\dfrac{1}{\ln(p)} \
        \Sum{k=1}{N} \dfrac{q^k}{k}$.

      \item Or, d'après la question \itbf{1.d)} de la partie $1$, pour
        tout $x \in [0, 1[$, la série $\Sum{k \geq 1}{}
        \dfrac{x^k}{k}$ est convergente, de somme $-\ln(1-x)$. En
        appliquant ce résultat à $x = p \in \ ]0, 1[$, on obtient que
        la série $\Sum{k \geq 1}{} u_k$ est convergente, de somme :
        \[
        \Sum{k = 1}{+\infty} u_k = - \dfrac{1}{\ln(p)} \ \Sum{k =
          1}{+\infty} \dfrac{q^k}{k} = - \dfrac{1}{\ln(p)} \ (-\ln(1-q))
        = - \dfrac{1}{\ln(p)} \ (-\ln(p)) = 1
        \]
      \end{noliste}
      \conc{$\Sum{k=1}{+\infty} u_k = 1$}~\\[-1cm]
    \end{proof}
  \end{noliste}
  On considère dorénavant une variable aléatoire $X$ dont la loi de
  probabilité est donnée par :
  \[
  \forall k\in\N^{*}, \ \Prob(\Ev{X = k}) = u_k
  \]
  
\item
  \begin{noliste}{a)}
    \setlength{\itemsep}{2mm}
  \item Montrer que $X$ possède une espérance et la déterminer.

    \begin{proof}~%
      \begin{noliste}{$\sbullet$}
      \item La \var $X$ admet une espérance si et seulement si la
        série $\Sum{k \geq 1}{} k \ u_k$ est absolument convergente.\\
        Cette série étant à termes positifs, cela revient à démontrer
        qu'elle est convergente.

      \item Soit $N \in \N^*$.
        \[
        \Sum{k = 1}{N} k \ u_k = \Sum{k = 1}{N} \dfrac{-q^k}{\ln(p)} =
        -\dfrac{1}{\ln(p)} \ \Sum{k = 1}{N} q^k
        \]

      \item Or, comme $q \in \ ]0, 1[$, la série $\Sum{k \geq 1}{}
        q^k$ est convergente.\\
        On en déduit que la \var $X$ admet une espérance, donnée par : 
        \[
        \E(X) = \Sum{k=1}{+\infty} k \ u_k = -\dfrac{1}{\ln(p)}
        \ \Sum{k=1}{+\infty} q^k = -\dfrac{1}{\ln(p)} \ \dfrac{q^1}{1-q}
        \]
      \end{noliste}
      \conc{La \var $X$ admet pour espérance $\E(X) = -\dfrac{q}{p \
          \ln(p)}$.}~\\[-1.1cm]
      ~\\[-1.2cm]
    \end{proof}


    %\newpage


  \item Montrer également que $X$ possède une variance et vérifier que
    : $\V(X) = \dfrac{-q \ (q + \ln(p))}{(p \ \ln(p))^{2}}$.

    \begin{proof}~%
      \begin{noliste}{$\sbullet$}
      \item La \var $X$ admet une variance si et seulement si la
        série $\Sum{k \geq 1}{} k^2 \ u_k$ est absolument convergente.\\
        Cette série étant à termes positifs, cela revient à démontrer
        qu'elle est convergente.

      \item Soit $N \in \N^*$.
        \[
        \Sum{k = 1}{N} k^2 \ u_k = \Sum{k = 1}{N} k^{\bcancel{2}} \
        \dfrac{-q^k}{\bcancel{k} \ \ln(p)} = -\dfrac{1}{\ln(p)} \
        \Sum{k = 1}{N} k \ q^k = -\dfrac{q}{\ln(p)} \ \Sum{k = 1}{N} k
        \ q^{k-1}
        \]

      \item Or, comme $q \in \ ]0, 1[$, la série $\Sum{k \geq 1}{}
        k \ q^{k-1}$ est convergente.\\
        On en déduit que la \var $X$ admet un moment d'ordre $2$,
        donné par :
        \[
        \E(X^2) = \Sum{k=1}{+\infty} k^2 \ u_k = -\dfrac{q}{\ln(p)} \
        \Sum{k=1}{+\infty} k \ q^{k-1} = -\dfrac{q}{\ln(p)} \
        \dfrac{1}{(1-q)^2} = -\dfrac{q}{p^2 \ \ln(p)}
        \]

      \item Enfin, par la formule de K\oe{}nig-Huygens :
        \[
        \begin{array}{rcl}
          \V(X) & = & \E(X^2) - (\E(X))^2 
          \\[.2cm]
          & = & -\dfrac{q}{p^2 \ \ln(p)} - \left( -\dfrac{q}{p \
              \ln(p)}\right)^2 
          \\[.4cm]
          & = & -\dfrac{q}{p^2 \ \ln(p)} - \dfrac{q^2}{p^2 \
            (\ln(p))^2} 
          \\[.6cm]
          & = & \dfrac{-q \ \ln(p) - q^2}{p^2 \ (\ln(p))^2} 
          % \\[.6cm]
          \ = \ \dfrac{-q \ (q + \ln(p))}{(p \ \ln(p))^2}
        \end{array}
        \]
        \conc{La \var $X$ admet pour variance $\V(X) = \dfrac{-q \ (q
            + \ln(p))}{(p \ \ln(p))^2}$.}
      \end{noliste}
      ~\\[-1.4cm]
    \end{proof}
  \end{noliste}

\item Soit $k$ un entier naturel non nul. On considère une variable
  aléatoire $Y$ dont la loi, conditionnellement à l'évènement $\Ev{X =
    k}$, est la loi binomiale de paramètres $k$ et $p$.

  \begin{noliste}{a)}
    \setlength{\itemsep}{2mm}
  \item Montrer que $Y(\Omega) = \N$ puis utiliser la formule des
    probabilités totales, ainsi que la question \itbf{1}) de la partie
    $1$, pour montrer que :
    \[
    \Prob(\Ev{Y = 0}) = 1 + \dfrac{\ln(1 + q)}{\ln(p)}
    \]


    %\newpage


    \begin{proof}~%
      \begin{noliste}{$\sbullet$}
      \item D'après l'énoncé, on sait que si l'événement $\Ev{X = k}$
        est réalisé alors $Y$ peut prendre toutes les valeurs de $\llb
        0, k \rrb$.
      \item Or $X(\Omega) = \N^*$. Autrement dit, $X$ peut prendre
        toutes les valeurs $k \in \N^*$.
      \end{noliste}
      On en déduit que $Y$ peut prendre toutes les valeurs de $\N$.%
      \conc{$Y(\Omega) = \N$}
      \begin{noliste}{$\sbullet$}
      \item La famille $\big(\Ev{X = k}\big)_{k \in \N^*}$ forme un
        système complet d'événements.\\
        Par la formule des probabilités totales :
        \[
        \begin{array}{rcl@{\quad}>{\it}R{5cm}}
          \Prob(\Ev{Y = 0}) & = & \Sum{k=1}{+\infty} \Prob(\Ev{X = k} \cap
          \Ev{Y = 0})
          \\[.4cm]
          & = & \Sum{k=1}{+\infty} \Prob(\Ev{X = k}) \times
          \Prob_{\Ev{X = k}}(\Ev{Y = 0}) 
          \\[.4cm]
          & = & \Sum{k=1}{+\infty} \dfrac{-q^k}{k \ \ln(p)} \times
          \dbinom{k}{0} \ p^0 \ (1-p)^k & (par définition de $X$ et
          $Y$)
          \nl
          \nl[-.2cm]
          & = & \dfrac{-1}{\ln(p)} \ \Sum{k=1}{+\infty} \dfrac{q^k}{k}
          \times q^k
          \\[.6cm]
          & = & \dfrac{-1}{\ln(p)} \ \Sum{k=1}{+\infty} \dfrac{(q^2)^k}{k}
          \\[.6cm]
          & = & \dfrac{\bcancel{-}1}{\ln(p)} \ (\bcancel{-} \ln(1 -
          q^2)) & (d'après la question \itbf{1.c)} partie $1$ avec $x
          = q^2 \in \ ]0,1[$) 
          \nl
          \nl[-.2cm]
          & = & \dfrac{1}{\ln(p)} \ (\ln((1 - q) (1 + q))) 
          \\[.6cm] 
          & = & \multicolumn{2}{l}{\dfrac{1}{\ln(p)} \ (\ln(p) + \ln(1
            + q)) \ = \ \dfrac{\ln(p)}{\ln(p)} + \dfrac{\ln(1 + q)}{\ln(p)}
          } 
        \end{array}
        \]
      \end{noliste}
      \conc{Ainsi, $\Prob(\Ev{Y = 0}) = 1 +
        \dfrac{\ln(1+q)}{\ln(p)}$}~\\[-1.2cm] 
    \end{proof}
    
  \item Après avoir montré que, pour tout couple $(k,n)$ de $\N^*
    \times \N^*$, on a : $\dfrac{\binom{k}{n}}{k} =
    \dfrac{\binom{k-1}{n-1}}{n}$, établir que, pour tout entier
    naturel $n$ non nul, on a :
    \[
    \Prob(\Ev{Y = n}) = -\dfrac{p^{n} \ q^{n}}{n \ \ln(p)} \ \Sum{k =
      n}{+ \infty} \dbinom{k-1}{n-1} \ \left(q^{2} \right)^{k-n}
    \]
    En déduire, grâce à la question \itbf{3)} de la première partie,
    l'égalité :
    \[
    \Prob(\Ev{Y = n}) = -\dfrac{q^{n}}{n \ (1 + q)^{n} \ \ln(p)}
    \]

    \begin{proof}~\\%
      Soit $(k, n) \in \N^* \times \N^*$. On doit démontrer :
        \[
        n \ \dbinom{k}{n} = k \ \dbinom{k-1}{n-1}
        \]
      \begin{noliste}{$\sbullet$}
      \item Remarquons tout d'abord que si $n > k$, alors $n-1 > k-1$
        et ainsi $\dbinom{k}{n} = \dbinom{k-1}{n-1} = 0$.


        %\newpage


      \item On suppose maintenant que $n \leq k$. Tout d'abord :
        \[
        n \ \dbinom{k}{n} = n \ \dfrac{k!}{n! \ (k-n)!} =
        \dfrac{k!}{(n-1)! \ (k-n)!}
        \]
        Par ailleurs : 
        \[
        k \ \dbinom{k-1}{n-1} = k \ \dfrac{(k-1)!}{(n-1)! \
          ((k-\bcancel{1})-(n-\bcancel{1}))!} = \dfrac{k!}{(n-1)! \
          (k-n)!}
        \]
        \conc{Ainsi : $\forall (k, n) \in \N^* \times \N^*$, $n \
          \dbinom{k}{n} = k \ \dbinom{k-1}{n-1}$.}

      \item La famille $\big(\Ev{X = k}\big)_{k \in \N^*}$ forme un
        système complet d'événements.\\
        Par la formule des probabilités totales :
        \[
        \begin{array}{rcl@{\qquad}>{\it}R{5cm}}
          \Prob(\Ev{Y = n}) & = & \Sum{k=1}{+\infty} \Prob(\Ev{X = k} \cap
          \Ev{Y = n})
          \\[.4cm]
          & = & \Sum{k=1}{+\infty} \Prob(\Ev{X = k}) \times
          \Prob_{\Ev{X = k}}(\Ev{Y = n}) 
          \\[.4cm]
          & = & \bcancel{\Sum{k=1}{n-1} \Prob(\Ev{X = k}) \times
          \Prob_{\Ev{X = k}}(\Ev{Y = n})} & (\ $\Prob_{\Ev{X =
            k}}(\Ev{Y = n}) = 0$ \\ si $k < n$) 
          \nl
          \nl[-.2cm]
          & + & \Sum{k=n}{+\infty} \Prob(\Ev{X = k}) \times
          \Prob_{\Ev{X = k}}(\Ev{Y = n}) 
          \\[.4cm]
          & = & \Sum{k=n}{+\infty} \dfrac{-q^k}{k \ \ln(p)} \times
          \dbinom{k}{n} \ p^n \ (1-p)^{k-n} & (par définition de $X$ et
          $Y$)
          \nl
          \nl[-.2cm]
          & = & -\dfrac{p^n}{\ln(p)} \ \Sum{k=n}{+\infty}
          \dfrac{\binom{k}{n}}{k} \ q^k \ q^{k-n} 
          \\[.6cm]
          & = & -\dfrac{p^n \ q^n}{\ln(p)} \ \Sum{k=n}{+\infty}
          \dfrac{\binom{k}{n}}{k} \ q^{k-n} \ q^{k-n} 
          \\[.6cm]
          & = & -\dfrac{p^n \ q^n}{\ln(p)} \ \Sum{k=n}{+\infty}
          \dfrac{\binom{k-1}{n-1}}{n} \ (q^2)^{k-n}
        \end{array}
        \]
        \conc{Ainsi, on a bien : $\Prob(\Ev{Y = n}) = -\dfrac{p^n \
            q^n}{n \ \ln(p)} \ \Sum{k=n}{+\infty} \dbinom{k-1}{n-1} \
          (q^2)^{k-n}$.} 

      \item Enfin : 
        \[
        \begin{array}{rcl@{\qquad}>{\it}R{5cm}}
          \Prob(\Ev{Y = n}) & = & -\dfrac{p^n \
            q^n}{n \ \ln(p)} \ \Sum{k=n}{+\infty} \dbinom{k-1}{n-1} \
          (1 - (1 - q^2))^{k-n} & (car $q^2 = 1 - (1 - q^2)$)
          \nl
          \nl[-.2cm]
          & = & -\dfrac{p^n \ q^n}{n \ \ln(p)} \ \dfrac{1}{(1 - q^2)^n}
          & (d'après la question \itbf{3.c)} \\ avec $x = 1-q^2 \in \ ]0,1[$)
          \nl
          \nl[-.2cm]
          & = & -\dfrac{\bcancel{p^n} \ q^n}{n \ \ln(p)} \
          \dfrac{1}{\bcancel{(1 - q)^n} \ (1 + q)^n}
        \end{array}
        \]
        \conc{On en conclut : $\forall n \in \N^*$, $\Prob(\Ev{Y = n})
          = -\dfrac{q^n}{n \ \ln(p) \ (1 + q)^n}$}
      \end{noliste}      


      %\newpage


      ~\\[-1.4cm]
    \end{proof}
    
  \item Vérifier que l'on a $\Sum{k = 0}{+ \infty}\Prob\left(\Ev{Y =
        k}\right) = 1.$

    \begin{proof}~%
      \begin{noliste}{$\sbullet$}
      \item Notons tout d'abord :
        \[
        \Sum{k = 0}{+\infty} \Prob(\Ev{Y = k}) \ = \ \Prob(\Ev{Y=0}) +
        \Sum{k = 1}{+\infty} \Prob(\Ev{Y = k})
        \]

      \item Or : 
        \[
        \begin{array}{rcl@{\qquad}>{\it}R{3.5cm}}
          \Sum{k = 1}{+\infty} \Prob(\Ev{Y = k}) & = & 
          \Sum{k=1}{+\infty} \dfrac{-q^k}{k \ (1+q)^k \ \ln(p)}
          & (d'après la \\ question \itbf{3.b)})
          \nl
          \nl[-.2cm]
          & = & \dfrac{-1}{\ln(p)} \ \Sum{k=1}{+\infty}
          \dfrac{\left(\frac{q}{1+q} \right)^k}{k}
          \\[.6cm]
          & = & \dfrac{\bcancel{-}1}{\ln(p)} \ (\bcancel{-} \ln\left(
            1 - \dfrac{q}{1+q} \right)) & (d'après \itbf{1.d)} \\ de la
          partie $1$ (*))
          \nl
          \nl[-.2cm]
          & = & \dfrac{1}{\ln(p)} \ \ln\left( \dfrac{1}{1+q} \right)
          \\[.6cm]
          & = & - \dfrac{\ln(1+q)}{\ln(p)}
        \end{array}
        \]
        {\it (*)} On peut utiliser ce résultat car $0 < q < 1+q$ et
        donc $0 < \dfrac{q}{1+q} < 1$.

      \item On en déduit, à l'aide de la question \itbf{3.a)} :
        \[
        \Sum{k = 0}{+\infty} \Prob(\Ev{Y = k}) \ = \ \left( 1 +
          \bcancel{\dfrac{\ln(1+q)}{\ln(p)}} \right) -
        \bcancel{\dfrac{\ln(1+q)}{\ln(p)}} \ = \ 1
        \]
      \end{noliste}
      \conc{On a bien : $\Sum{k = 0}{+\infty} \Prob(\Ev{Y = k}) =
        1$.}~\\[-1.2cm] 
    \end{proof}
    

    %\newpage


  \item Montrer que $Y$ possède une espérance et donner son expression
    en fonction de $\ln(p)$ et $q$.

    \begin{proof}~%
      \begin{noliste}{$\sbullet$}
      \item La \var $Y$ admet une espérance si et seulement si la
        série $\Serie k \ \Prob(\Ev{Y = k})$ est absolument
        convergente. Cette série étant à termes positifs, cela
        revient à démontrer qu'elle est convergente.

      \item Soit $N \in \N$.
        \[
        \begin{array}{rcl}
          \Sum{k = 0}{N} k \ \Prob(\Ev{Y = k}) & = & 0 \times \Prob(\Ev{Y =
            0}) + \Sum{k = 1}{N} k \ \Prob(\Ev{Y = k}) 
          \\[.4cm]
          & = & \Sum{k = 1}{N} \bcancel{k} \ \dfrac{-q^k}{\bcancel{k}
            \ \ln(p) \ (1+q)^k} 
          \\[.6cm]
          & = & \dfrac{-1}{\ln(p)} \ \Sum{k = 1}{N}
          \left(\dfrac{q}{1+q} \right)^k 
        \end{array}
        \]

      \item Or, comme $\frac{q}{1+q} \in \ ]0, 1[$, la série $\Sum{k
          \geq 1}{} \left( \frac{q}{1+q} \right)^k$ est convergente.\\
        On en déduit que la \var $X$ admet une espérance, donnée par :
        \[
        \begin{array}{rcl}
          \E(Y) & = & \Sum{k=0}{+\infty} k \ \Prob(\Ev{Y = k}) 
          \\[.2cm]
          & = & -\dfrac{1}{\ln(p)} \ \Sum{k=1}{+\infty} \left(\dfrac{q}{1+q}
          \right)^k 
          \\[.4cm]
          & = & -\dfrac{1}{\ln(p)} \ \dfrac{\left( \frac{q}{1+q}
            \right)^1}{1 - \frac{q}{1+q}}
          \\[.6cm]
          & = & -\dfrac{1}{\ln(p)} \ \dfrac{q}{1+q} \ \dfrac{1}{1 -
            \frac{q}{1+q}} 
          \\[.6cm]
          & = & -\dfrac{1}{\ln(p)} \ \dfrac{q}{(1 + \bcancel{q}) -
            \bcancel{q}} \ = \ - \dfrac{q}{\ln(p)}
        \end{array}
        \]

        \conc{La \var $Y$ admet pour espérance $\E(Y) = -
          \dfrac{q}{\ln(p)}$.}~\\[-1.4cm]
      \end{noliste}
    \end{proof}

  \item Montrer aussi que $Y$ possède une variance et que l'on a :
    $\V(Y) = -\dfrac{q \ (q + (1 + q) \ \ln(p))}{(\ln(p))^{2}}$.

    \begin{proof}~%
      \begin{noliste}{$\sbullet$}
      \item La \var $Y$ admet une variance si et seulement si la série
        $\Sum{k \geq 0}{} k^2 \ \Prob(\Ev{Y = k})$ est absolument
        convergente. Cette série étant à termes positifs, cela
        revient à démontrer qu'elle est convergente.

      \item Soit $N \in \N$.
        \[
        \begin{array}{rcl}
          \Sum{k = 0}{N} k^2 \ \Prob(\Ev{Y = k}) & = & 0^2 \times
          \Prob(\Ev{Y = 0}) + \Sum{k = 1}{N} k^2 \ \Prob(\Ev{Y = k}) 
          \\[.4cm]
          & = & \Sum{k = 1}{N} k^{\bcancel{2}} \ \dfrac{-q^k}{\bcancel{k}
            \ \ln(p) \ (1+q)^k} 
          \\[.6cm]
          & = & \dfrac{-1}{\ln(p)} \ \Sum{k = 1}{N} k \ 
          \left(\dfrac{q}{1+q} \right)^k 
          \\[.6cm]
          & = & \dfrac{-q}{(1+q) \ \ln(p)} \ \Sum{k = 1}{N} k \ 
          \left(\dfrac{q}{1+q} \right)^{k-1} 
        \end{array}
        \]


        %\newpage


      \item Or, comme $\frac{q}{1+q} \in \ ]0, 1[$, la série $\Serie k
        \ \left( \frac{q}{1+q} \right)^{k-1}$ est convergente.\\
        On en déduit que la \var $Y$ admet un moment d'ordre $2$,
        donné par :
        \[
        \begin{array}{rcl}
          \E(Y^2) & = & \Sum{k=0}{+\infty} k^2 \ \Prob(\Ev{Y = k}) 
          \\[.4cm]
          & = & -\dfrac{q}{(1+q) \ \ln(p)} \ \Sum{k=1}{+\infty} k \ \left(
            \dfrac{q}{1+q} \right)^{k-1} 
          \\[.6cm]
          & = & -\dfrac{q}{(1+q) \ \ln(p)} \ \dfrac{1}{\left( 1 -
              \frac{q}{1+q} \right)^2} 
          \\[.8cm]
          & = & -\dfrac{q}{\bcancel{(1+q)} \ \ln(p)} \ \dfrac{(1 +
            q)^{\bcancel{2}}}{\left( (1+q) - q \right)^2} 
          %\\[.6cm]
          \ = \ - \dfrac{q \ (1+q)}{\ln(p)}
        \end{array}
        \]

      \item Enfin, par la formule de K\oe{}nig-Huygens :
        \[
        \begin{array}{rcl}
          \V(Y) & = & \E(Y^2) - (\E(Y))^2 
          \\[.2cm]
          & = & - \dfrac{q \ (1+q)}{\ln(p)} - \left( -
            \dfrac{q}{\ln(p)} \right)^2
          \\[.4cm]
          & = & - \dfrac{q \ (1+q)}{\ln(p)} - \dfrac{q^2}{(\ln(p))^2}
          \\[.4cm]
          & = & - \dfrac{q \ (1+q) \ \ln(p) + q^2}{(\ln(p))^2}
          \\[.4cm]
          & = & - \dfrac{q \ \left( (1+q) \ \ln(p) + q \right)}{(\ln(p))^2}
        \end{array}
        \]
        \conc{La \var $Y$ admet pour variance $\V(Y) = - \dfrac{q \
            \left( (1+q) \ \ln(p) + q \right)}{(\ln(p))^2}$.}       
      \end{noliste}
      ~\\[-1.2cm]
    \end{proof}
  \end{noliste}
\end{noliste}

\end{document}

